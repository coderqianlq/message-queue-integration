2020-04-07 11:06:33 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:308 - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.qianlq.producer.kafka.KafkaTest], using SpringBootContextLoader
2020-04-07 11:06:33 [Thread: main] [ INFO ] AbstractContextLoader:264 - Could not detect default resource locations for test class [com.qianlq.producer.kafka.KafkaTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2020-04-07 11:06:33 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2020-04-07 11:06:33 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:177 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@7fbbdd8a, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4e9ea32f, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@79ec57b8, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@56ba8e8c, org.springframework.test.context.support.DirtiesContextTestExecutionListener@774c5e5c, org.springframework.test.context.transaction.TransactionalTestExecutionListener@4cf01c41, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@57bac3f0, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@55f6f965, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@40ddf339, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@c83ed77, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@d271a54, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@6ff8e744]
2020-04-07 11:06:34 [Thread: main] [ INFO ] Log4jControllerRegistration$:31 - Registered kafka:type=kafka.Log4jController MBean
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:host.name=192.168.0.105
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.version=1.8.0_161
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.vendor=Oracle Corporation
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.class.path=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.compiler=<NA>
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.name=Mac OS X
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.arch=x86_64
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.version=10.15.3
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.name=qianliqing
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.home=/Users/qianliqing
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-04-07 11:06:34 [Thread: main] [ INFO ] ZooKeeperServer:174 - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4789941590108559079/version-2 snapdir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3487396150423059473/version-2
2020-04-07 11:06:34 [Thread: main] [ INFO ] NIOServerCnxnFactory:89 - binding to port /127.0.0.1:0
2020-04-07 11:06:35 [Thread: ZkClient-EventThread-20-127.0.0.1:54518] [ INFO ] ZkEventThread:65 - Starting ZkClient event thread.
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:host.name=192.168.0.105
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.version=1.8.0_161
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.class.path=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.compiler=<NA>
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.name=Mac OS X
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.arch=x86_64
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.version=10.15.3
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.name=qianliqing
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.home=/Users/qianliqing
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:54518 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@66a5cbe5
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZkClient:936 - Waiting for keeper state SyncConnected
2020-04-07 11:06:35 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:54518. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 11:06:35 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:54518, initiating session
2020-04-07 11:06:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:54519
2020-04-07 11:06:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:54519
2020-04-07 11:06:35 [Thread: SyncThread:0] [ INFO ] FileTxnLog:213 - Creating new log file: log.1
2020-04-07 11:06:35 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100028d270a0000 with negotiated timeout 6000 for client /127.0.0.1:54519
2020-04-07 11:06:35 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:54518, sessionid = 0x100028d270a0000, negotiated timeout = 6000
2020-04-07 11:06:35 [Thread: main-EventThread] [ INFO ] ZkClient:713 - zookeeper state changed (SyncConnected)
2020-04-07 11:06:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4661499049755691486
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:35 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-04-07 11:06:35 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:54518
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:54518.
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:54518 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6b7b046
2020-04-07 11:06:35 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:54518. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 11:06:35 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:54518, initiating session
2020-04-07 11:06:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:54523
2020-04-07 11:06:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:54523
2020-04-07 11:06:35 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100028d270a0001 with negotiated timeout 6000 for client /127.0.0.1:54523
2020-04-07 11:06:35 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:54518, sessionid = 0x100028d270a0001, negotiated timeout = 6000
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-04-07 11:06:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-04-07 11:06:35 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2020-04-07 11:06:35 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2020-04-07 11:06:35 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2020-04-07 11:06:36 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2020-04-07 11:06:36 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = 2vJGyOqtRSSy9KMS6oL-aQ
2020-04-07 11:06:36 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4661499049755691486/meta.properties
2020-04-07 11:06:36 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4661499049755691486
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:36 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4661499049755691486
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:36 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-04-07 11:06:36 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-04-07 11:06:36 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-04-07 11:06:36 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-04-07 11:06:36 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 14 ms.
2020-04-07 11:06:36 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-04-07 11:06:36 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-04-07 11:06:36 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-04-07 11:06:36 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-04-07 11:06:36 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9092.
2020-04-07 11:06:36 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started 1 acceptor threads
2020-04-07 11:06:36 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Starting
2020-04-07 11:06:36 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Starting
2020-04-07 11:06:36 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Starting
2020-04-07 11:06:36 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-04-07 11:06:36 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/0 (is it secure? false)
2020-04-07 11:06:36 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/0 is: OK
2020-04-07 11:06:36 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT))
2020-04-07 11:06:36 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4661499049755691486/meta.properties
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Starting
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 11:06:37 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Starting
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] 0 successfully elected as the controller
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Reading controller epoch from ZooKeeper
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Incrementing controller epoch in ZooKeeper
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0001 type:setData cxid:0x21 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2020-04-07 11:06:37 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Starting
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Epoch incremented to 1
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Registering handlers
2020-04-07 11:06:37 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Starting
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting log dir event notifications
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting isr change notifications
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing controller context
2020-04-07 11:06:37 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Starting up.
2020-04-07 11:06:37 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Startup complete.
2020-04-07 11:06:37 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds.
2020-04-07 11:06:37 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2020-04-07 11:06:37 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Starting up.
2020-04-07 11:06:37 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions being reassigned: Map()
2020-04-07 11:06:37 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Startup complete.
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently active brokers in the cluster: Set(0)
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently shutting brokers in the cluster: Set()
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Current list of topics in the cluster: Set()
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Fetching topic deletions in progress
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics to be deleted: 
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics ineligible for deletion: 
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing topic deletion manager
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Sending update metadata request
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Initializing replica state
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2020-04-07 11:06:37 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9092 (id: 0 rack: null) for sending state change requests
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Started replica state machine with initial state -> Map()
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Initializing partition state
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Triggering online partition state changes
2020-04-07 11:06:37 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Started partition state machine with initial state -> Map()
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Ready to serve as the new controller with epoch 1
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0001 type:delete cxid:0x37 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-04-07 11:06:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started processors for 1 acceptors
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions undergoing preferred replica election: 
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions that completed preferred replica election: 
2020-04-07 11:06:37 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 11:06:37 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Resuming preferred replica election for partitions: 
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting preferred replica leader election for partitions 
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] started
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0001 type:delete cxid:0x39 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1993400207578155708
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:54518
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:54518.
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:54518 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@28a16598
2020-04-07 11:06:37 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:54518. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 11:06:37 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:54528
2020-04-07 11:06:37 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:54518, initiating session
2020-04-07 11:06:37 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:54528
2020-04-07 11:06:37 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100028d270a0002 with negotiated timeout 6000 for client /127.0.0.1:54528
2020-04-07 11:06:37 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:54518, sessionid = 0x100028d270a0002, negotiated timeout = 6000
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x1 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting the controller scheduler
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x2 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x3 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x4 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x5 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x6 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x7 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x8 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x9 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0xa zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0xb zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0xc zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0xd zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = 2vJGyOqtRSSy9KMS6oL-aQ
2020-04-07 11:06:37 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1993400207578155708/meta.properties
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1993400207578155708
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1993400207578155708
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:37 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-04-07 11:06:37 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-04-07 11:06:37 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 1 ms.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-04-07 11:06:37 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9093.
2020-04-07 11:06:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started 1 acceptor threads
2020-04-07 11:06:37 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Starting
2020-04-07 11:06:37 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Starting
2020-04-07 11:06:37 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Starting
2020-04-07 11:06:37 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/1 (is it secure? false)
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/1 is: OK
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT))
2020-04-07 11:06:37 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1993400207578155708/meta.properties
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Starting
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 1, deleted brokers: , all live brokers: 0,1
2020-04-07 11:06:37 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Starting
2020-04-07 11:06:37 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Starting
2020-04-07 11:06:37 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Starting up.
2020-04-07 11:06:37 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-04-07 11:06:37 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds.
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 1
2020-04-07 11:06:37 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-04-07 11:06:37 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Startup complete.
2020-04-07 11:06:37 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2020-04-07 11:06:37 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Starting up.
2020-04-07 11:06:37 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Startup complete.
2020-04-07 11:06:37 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started processors for 1 acceptors
2020-04-07 11:06:37 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 11:06:37 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] started
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2142763693714325883
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:54518
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:54518.
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:54518 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4b693be7
2020-04-07 11:06:37 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:54518. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 11:06:37 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:54518, initiating session
2020-04-07 11:06:37 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:54534
2020-04-07 11:06:37 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:54534
2020-04-07 11:06:37 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:54518, sessionid = 0x100028d270a0003, negotiated timeout = 6000
2020-04-07 11:06:37 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100028d270a0003 with negotiated timeout 6000 for client /127.0.0.1:54534
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0x1 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0x2 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0x3 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0x4 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0x5 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0x6 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0x7 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0x8 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0x9 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0xa zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0xb zxid:0x3b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0xc zxid:0x3c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:create cxid:0xd zxid:0x3d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = 2vJGyOqtRSSy9KMS6oL-aQ
2020-04-07 11:06:37 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2142763693714325883/meta.properties
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2142763693714325883
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2142763693714325883
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:37 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-04-07 11:06:37 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-04-07 11:06:37 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 1 ms.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-04-07 11:06:37 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9094.
2020-04-07 11:06:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started 1 acceptor threads
2020-04-07 11:06:37 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Starting
2020-04-07 11:06:37 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Starting
2020-04-07 11:06:37 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Starting
2020-04-07 11:06:37 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/2 (is it secure? false)
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/2 is: OK
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT))
2020-04-07 11:06:37 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2142763693714325883/meta.properties
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Starting
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 2, deleted brokers: , all live brokers: 0,1,2
2020-04-07 11:06:37 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Starting
2020-04-07 11:06:37 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Starting
2020-04-07 11:06:37 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 2
2020-04-07 11:06:37 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-04-07 11:06:37 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-04-07 11:06:37 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Starting up.
2020-04-07 11:06:37 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2020-04-07 11:06:37 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Startup complete.
2020-04-07 11:06:37 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2020-04-07 11:06:37 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Starting up.
2020-04-07 11:06:37 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Startup complete.
2020-04-07 11:06:37 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started processors for 1 acceptors
2020-04-07 11:06:37 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 11:06:37 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] started
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3311787846110841863
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:54518
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:54518.
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:54518 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3c95bbb4
2020-04-07 11:06:37 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:54518. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-04-07 11:06:37 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:54536
2020-04-07 11:06:37 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:54518, initiating session
2020-04-07 11:06:37 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:54536
2020-04-07 11:06:37 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100028d270a0004 with negotiated timeout 6000 for client /127.0.0.1:54536
2020-04-07 11:06:37 [Thread: main-SendThread(localhost:54518)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:54518, sessionid = 0x100028d270a0004, negotiated timeout = 6000
2020-04-07 11:06:37 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x1 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x3 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x4 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x5 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x6 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x7 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x8 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x9 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0xa zxid:0x4a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0xb zxid:0x4b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0xc zxid:0x4c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-04-07 11:06:37 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0xd zxid:0x4d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = 2vJGyOqtRSSy9KMS6oL-aQ
2020-04-07 11:06:37 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3311787846110841863/meta.properties
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3311787846110841863
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3311787846110841863
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:54518
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 11:06:37 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-04-07 11:06:37 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-04-07 11:06:37 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 2 ms.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-04-07 11:06:37 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-04-07 11:06:37 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9095.
2020-04-07 11:06:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started 1 acceptor threads
2020-04-07 11:06:37 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Starting
2020-04-07 11:06:37 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Starting
2020-04-07 11:06:37 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Starting
2020-04-07 11:06:37 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-04-07 11:06:37 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/3 (is it secure? false)
2020-04-07 11:06:38 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/3 is: OK
2020-04-07 11:06:38 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT))
2020-04-07 11:06:38 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3311787846110841863/meta.properties
2020-04-07 11:06:38 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 3, deleted brokers: , all live brokers: 0,1,2,3
2020-04-07 11:06:38 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Starting
2020-04-07 11:06:38 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Starting
2020-04-07 11:06:38 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-04-07 11:06:38 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 3
2020-04-07 11:06:38 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-04-07 11:06:38 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Starting
2020-04-07 11:06:38 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Starting
2020-04-07 11:06:38 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Starting up.
2020-04-07 11:06:38 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds.
2020-04-07 11:06:38 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Startup complete.
2020-04-07 11:06:38 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4
2020-04-07 11:06:38 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Starting up.
2020-04-07 11:06:38 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Startup complete.
2020-04-07 11:06:38 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Starting
2020-04-07 11:06:38 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-04-07 11:06:38 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started processors for 1 acceptors
2020-04-07 11:06:38 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 11:06:38 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 11:06:38 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] started
2020-04-07 11:06:38 [Thread: main] [ INFO ] AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092, 127.0.0.1:9093, 127.0.0.1:9094, 127.0.0.1:9095]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-04-07 11:06:38 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 11:06:38 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 11:06:38 [Thread: kafka-admin-client-thread | adminclient-1] [ INFO ] AdminMetadataManager:238 - [AdminClient clientId=adminclient-1] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: Timed out waiting to send the call.
2020-04-07 11:06:38 [Thread: main] [ INFO ] KafkaTest:50 - Starting KafkaTest on 192.168.0.105 with PID 15893 (started by qianliqing in /Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer)
2020-04-07 11:06:38 [Thread: main] [ INFO ] KafkaTest:675 - No active profile set, falling back to default profiles: default
2020-04-07 11:06:38 [Thread: main] [ INFO ] KafkaTest:59 - Started KafkaTest in 4.481 seconds (JVM running for 7.28)
2020-04-07 11:06:38 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shutting down
2020-04-07 11:06:38 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-04-07 11:06:38 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-04-07 11:06:38 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-04-07 11:06:38 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopping socket server request processors
2020-04-07 11:06:38 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopped socket server request processors
2020-04-07 11:06:38 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shutting down
2020-04-07 11:06:38 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shut down completely
2020-04-07 11:06:38 [Thread: Thread-10] [ INFO ] KafkaApis:66 - [KafkaApi-0] Shutdown complete.
2020-04-07 11:06:38 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutting down
2020-04-07 11:06:39 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutting down.
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 0]: Shutdown complete
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutting down
2020-04-07 11:06:39 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutdown complete.
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutting down.
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutting down
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutdown completed
2020-04-07 11:06:39 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutting down
2020-04-07 11:06:39 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutdown complete.
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shutting down
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-04-07 11:06:39 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutting down
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutting down
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutting down
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutdown completed
2020-04-07 11:06:39 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutting down
2020-04-07 11:06:39 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutting down
2020-04-07 11:06:39 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shut down completely
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutting down.
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-04-07 11:06:39 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4661499049755691486/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4661499049755691486/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutdown complete.
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutting down
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Stopped partition state machine
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Stopped replica state machine
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-04-07 11:06:39 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-04-07 11:06:39 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-04-07 11:06:39 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-04-07 11:06:39 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] KafkaController:66 - [Controller id=0] Resigned
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-04-07 11:06:39 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100028d270a0001
2020-04-07 11:06:39 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100028d270a0001
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100028d270a0001 closed
2020-04-07 11:06:39 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:54523 which had sessionid 0x100028d270a0001
2020-04-07 11:06:39 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100028d270a0001
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-04-07 11:06:39 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 11:06:39 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:create cxid:0x26 zxid:0x52 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-04-07 11:06:39 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0002 type:create cxid:0x24 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] 2 successfully elected as the controller
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Reading controller epoch from ZooKeeper
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Initialized controller epoch to 1 and zk version 0
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Incrementing controller epoch in ZooKeeper
2020-04-07 11:06:39 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72060399306539011' does not match current session '72060399306539012'
2020-04-07 11:06:39 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72060399306539011' does not match current session '72060399306539010'
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Epoch incremented to 2
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Registering handlers
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Deleting log dir event notifications
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Deleting isr change notifications
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Initializing controller context
2020-04-07 11:06:39 [Thread: Controller-2-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Starting
2020-04-07 11:06:39 [Thread: Controller-2-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Starting
2020-04-07 11:06:39 [Thread: Controller-2-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Starting
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Partitions being reassigned: Map()
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Currently active brokers in the cluster: Set(1, 2, 3)
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Currently shutting brokers in the cluster: Set()
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Current list of topics in the cluster: Set()
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Fetching topic deletions in progress
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] List of topics to be deleted: 
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] List of topics ineligible for deletion: 
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Initializing topic deletion manager
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Sending update metadata request
2020-04-07 11:06:39 [Thread: Controller-2-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Controller 2 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-04-07 11:06:39 [Thread: Controller-2-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Controller 2 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-04-07 11:06:39 [Thread: Controller-2-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Controller 2 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=2] Initializing replica state
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=2] Triggering online replica state changes
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map()
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=2] Initializing partition state
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=2] Triggering online partition state changes
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map()
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Ready to serve as the new controller with epoch 2
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-04-07 11:06:39 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:delete cxid:0x36 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Partitions undergoing preferred replica election: 
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Partitions that completed preferred replica election: 
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Skipping preferred replica election for partitions due to topic deletion: 
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Resuming preferred replica election for partitions: 
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Starting preferred replica leader election for partitions 
2020-04-07 11:06:39 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0003 type:delete cxid:0x38 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-04-07 11:06:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Starting the controller scheduler
2020-04-07 11:06:40 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-04-07 11:06:40 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-04-07 11:06:40 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-04-07 11:06:41 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-04-07 11:06:41 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-04-07 11:06:41 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-04-07 11:06:42 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutting down socket server
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutdown completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shut down completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shutting down
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-04-07 11:06:42 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopping socket server request processors
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopped socket server request processors
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shutting down
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shut down completely
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] KafkaApis:66 - [KafkaApi-1] Shutdown complete.
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutting down
2020-04-07 11:06:42 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Stopped
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutdown completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutting down.
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 1]: Shutdown complete
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutting down
2020-04-07 11:06:42 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Stopped
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutdown completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutdown complete.
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutting down.
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutting down
2020-04-07 11:06:42 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Stopped
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutting down
2020-04-07 11:06:42 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Stopped
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutdown complete.
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shutting down
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-04-07 11:06:42 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutting down
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutdown completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutting down
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2020-04-07 11:06:42 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutting down
2020-04-07 11:06:43 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Stopped
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutdown completed
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutting down
2020-04-07 11:06:43 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Stopped
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutdown completed
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2020-04-07 11:06:43 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Stopped
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shut down completely
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutting down.
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-04-07 11:06:43 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-04-07 11:06:43 [Thread: Thread-10] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1993400207578155708/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1993400207578155708/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutdown complete.
2020-04-07 11:06:43 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutting down
2020-04-07 11:06:43 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Stopped
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutdown completed
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] KafkaController:66 - [Controller id=1] Resigned
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-04-07 11:06:43 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100028d270a0002
2020-04-07 11:06:43 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100028d270a0002
2020-04-07 11:06:43 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:54528 which had sessionid 0x100028d270a0002
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100028d270a0002 closed
2020-04-07 11:06:43 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100028d270a0002
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-04-07 11:06:43 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Newly added brokers: , deleted brokers: 1, all live brokers: 2,3
2020-04-07 11:06:43 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Shutting down
2020-04-07 11:06:43 [Thread: Controller-2-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Stopped
2020-04-07 11:06:43 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Shutdown completed
2020-04-07 11:06:43 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Broker failure callback for 1
2020-04-07 11:06:43 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=2] Removed ArrayBuffer() from list of shutting down brokers.
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-04-07 11:06:43 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-04-07 11:06:43 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-04-07 11:06:43 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-04-07 11:06:44 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutting down socket server
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shut down completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shutting down
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-04-07 11:06:44 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopping socket server request processors
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopped socket server request processors
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shutting down
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shut down completely
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] KafkaApis:66 - [KafkaApi-2] Shutdown complete.
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutting down
2020-04-07 11:06:44 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Stopped
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutting down.
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 2000
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 2]: Shutdown complete
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutting down
2020-04-07 11:06:44 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Stopped
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutdown complete.
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutting down.
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutting down
2020-04-07 11:06:44 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Stopped
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutting down
2020-04-07 11:06:44 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Stopped
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutdown complete.
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shutting down
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-04-07 11:06:44 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutting down
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutting down
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutdown completed
2020-04-07 11:06:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutting down
2020-04-07 11:06:45 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Stopped
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutdown completed
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutting down
2020-04-07 11:06:45 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Stopped
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutdown completed
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2020-04-07 11:06:45 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Stopped
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shut down completely
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutting down.
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-04-07 11:06:45 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-04-07 11:06:45 [Thread: Thread-10] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2142763693714325883/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2142763693714325883/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutdown complete.
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutting down
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Stopped
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutdown completed
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Shutting down
2020-04-07 11:06:45 [Thread: Controller-2-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Stopped
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Shutdown completed
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Shutting down
2020-04-07 11:06:45 [Thread: Controller-2-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Stopped
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=2] Shutdown completed
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] KafkaController:66 - [Controller id=2] Resigned
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-04-07 11:06:45 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100028d270a0003
2020-04-07 11:06:45 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100028d270a0003
2020-04-07 11:06:45 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:54534 which had sessionid 0x100028d270a0003
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100028d270a0003 closed
2020-04-07 11:06:45 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100028d270a0003
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] 3 successfully elected as the controller
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Reading controller epoch from ZooKeeper
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initialized controller epoch to 2 and zk version 1
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Incrementing controller epoch in ZooKeeper
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Epoch incremented to 3
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Registering handlers
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting log dir event notifications
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting isr change notifications
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing controller context
2020-04-07 11:06:45 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions being reassigned: Map()
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently active brokers in the cluster: Set(3)
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Current list of topics in the cluster: Set()
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Fetching topic deletions in progress
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics to be deleted: 
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics ineligible for deletion: 
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing topic deletion manager
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Sending update metadata request
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Initializing replica state
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Triggering online replica state changes
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Initializing partition state
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Triggering online partition state changes
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Ready to serve as the new controller with epoch 3
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-04-07 11:06:45 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-04-07 11:06:45 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:delete cxid:0x3b zxid:0x5b txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions undergoing preferred replica election: 
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions that completed preferred replica election: 
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Resuming preferred replica election for partitions: 
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting preferred replica leader election for partitions 
2020-04-07 11:06:45 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100028d270a0004 type:delete cxid:0x3d zxid:0x5c txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-04-07 11:06:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting the controller scheduler
2020-04-07 11:06:45 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-04-07 11:06:45 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-04-07 11:06:46 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-04-07 11:06:46 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-04-07 11:06:46 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-04-07 11:06:47 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutting down socket server
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutdown completed
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shut down completed
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shutting down
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-04-07 11:06:47 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopping socket server request processors
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopped socket server request processors
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shutting down
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shut down completely
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] KafkaApis:66 - [KafkaApi-3] Shutdown complete.
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutting down
2020-04-07 11:06:47 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Stopped
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutdown completed
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutting down.
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 3000
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 3]: Shutdown complete
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutting down
2020-04-07 11:06:47 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Stopped
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutdown completed
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutdown complete.
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutting down.
2020-04-07 11:06:47 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutting down
2020-04-07 11:06:48 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutting down
2020-04-07 11:06:48 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutdown complete.
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shutting down
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-04-07 11:06:48 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutting down
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutting down
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutting down
2020-04-07 11:06:48 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutting down
2020-04-07 11:06:48 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2020-04-07 11:06:48 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shut down completely
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutting down.
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-04-07 11:06:48 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3311787846110841863/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3311787846110841863/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutdown complete.
2020-04-07 11:06:48 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutting down
2020-04-07 11:06:48 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-04-07 11:06:48 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] KafkaController:66 - [Controller id=3] Resigned
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-04-07 11:06:48 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100028d270a0004
2020-04-07 11:06:48 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100028d270a0004
2020-04-07 11:06:48 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100028d270a0004
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100028d270a0004 closed
2020-04-07 11:06:48 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:54536 which had sessionid 0x100028d270a0004
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-04-07 11:06:48 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-04-07 11:06:48 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-04-07 11:06:49 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-04-07 11:06:49 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-04-07 11:06:49 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-04-07 11:06:50 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutting down socket server
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutdown completed
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shut down completed
2020-04-07 11:06:50 [Thread: ZkClient-EventThread-20-127.0.0.1:54518] [ INFO ] ZkEventThread:83 - Terminate ZkClient event thread.
2020-04-07 11:06:50 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100028d270a0000
2020-04-07 11:06:50 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100028d270a0000
2020-04-07 11:06:50 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:54519 which had sessionid 0x100028d270a0000
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100028d270a0000 closed
2020-04-07 11:06:50 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100028d270a0000
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] ZooKeeperServer:502 - shutting down
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] SessionTrackerImpl:226 - Shutting down
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] PrepRequestProcessor:769 - Shutting down
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] SyncRequestProcessor:208 - Shutting down
2020-04-07 11:06:50 [Thread: ProcessThread(sid:0 cport:54518):] [ INFO ] PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2020-04-07 11:06:50 [Thread: SyncThread:0] [ INFO ] SyncRequestProcessor:186 - SyncRequestProcessor exited!
2020-04-07 11:06:50 [Thread: Thread-10] [ INFO ] FinalRequestProcessor:403 - shutdown of request processor complete
2020-04-07 11:06:50 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2020-04-07 11:06:51 [Thread: SessionTracker] [ INFO ] SessionTrackerImpl:163 - SessionTrackerImpl exited loop!
2020-04-07 15:59:39 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:308 - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.qianlq.producer.kafka.KafkaTest], using SpringBootContextLoader
2020-04-07 15:59:39 [Thread: main] [ INFO ] AbstractContextLoader:264 - Could not detect default resource locations for test class [com.qianlq.producer.kafka.KafkaTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2020-04-07 15:59:39 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2020-04-07 15:59:39 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:177 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@79273a4f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4e26987b, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@50bb1c1f, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@39342614, org.springframework.test.context.support.DirtiesContextTestExecutionListener@7981963f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@31e3c34, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@b4d83ac, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@13d10057, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@66944c7c, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@14993306, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@73ae82da, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@6866e740]
2020-04-07 15:59:40 [Thread: main] [ INFO ] Log4jControllerRegistration$:31 - Registered kafka:type=kafka.Log4jController MBean
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:host.name=192.168.0.105
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.version=1.8.0_161
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.vendor=Oracle Corporation
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.class.path=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.compiler=<NA>
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.name=Mac OS X
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.arch=x86_64
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.version=10.15.3
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.name=qianliqing
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.home=/Users/qianliqing
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeperServer:174 - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7582475112933325652/version-2 snapdir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6191190829735523304/version-2
2020-04-07 15:59:40 [Thread: main] [ INFO ] NIOServerCnxnFactory:89 - binding to port /127.0.0.1:0
2020-04-07 15:59:40 [Thread: ZkClient-EventThread-20-127.0.0.1:59325] [ INFO ] ZkEventThread:65 - Starting ZkClient event thread.
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:host.name=192.168.0.105
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.version=1.8.0_161
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.class.path=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.compiler=<NA>
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.name=Mac OS X
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.arch=x86_64
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.version=10.15.3
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.name=qianliqing
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.home=/Users/qianliqing
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59325 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@74a46f81
2020-04-07 15:59:40 [Thread: main] [ INFO ] ZkClient:936 - Waiting for keeper state SyncConnected
2020-04-07 15:59:40 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59325. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 15:59:40 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59325, initiating session
2020-04-07 15:59:40 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59326
2020-04-07 15:59:40 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59326
2020-04-07 15:59:40 [Thread: SyncThread:0] [ INFO ] FileTxnLog:213 - Creating new log file: log.1
2020-04-07 15:59:40 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100035e711e0000 with negotiated timeout 6000 for client /127.0.0.1:59326
2020-04-07 15:59:40 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59325, sessionid = 0x100035e711e0000, negotiated timeout = 6000
2020-04-07 15:59:40 [Thread: main-EventThread] [ INFO ] ZkClient:713 - zookeeper state changed (SyncConnected)
2020-04-07 15:59:41 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7152749492694360216
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:41 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-04-07 15:59:41 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:59325
2020-04-07 15:59:41 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:59325.
2020-04-07 15:59:41 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59325 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5d1b4556
2020-04-07 15:59:41 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59325. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 15:59:41 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59325, initiating session
2020-04-07 15:59:41 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59327
2020-04-07 15:59:41 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59327
2020-04-07 15:59:41 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-04-07 15:59:41 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100035e711e0001 with negotiated timeout 6000 for client /127.0.0.1:59327
2020-04-07 15:59:41 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59325, sessionid = 0x100035e711e0001, negotiated timeout = 6000
2020-04-07 15:59:41 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-04-07 15:59:41 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2020-04-07 15:59:41 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2020-04-07 15:59:41 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2020-04-07 15:59:41 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2020-04-07 15:59:41 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = nhrQJ8WvTD-t_j1Fn4aLZg
2020-04-07 15:59:41 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7152749492694360216/meta.properties
2020-04-07 15:59:41 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7152749492694360216
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:41 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7152749492694360216
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:41 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-04-07 15:59:41 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-04-07 15:59:41 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-04-07 15:59:41 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-04-07 15:59:41 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 14 ms.
2020-04-07 15:59:41 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-04-07 15:59:41 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-04-07 15:59:41 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-04-07 15:59:41 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-04-07 15:59:42 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9092.
2020-04-07 15:59:42 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started 1 acceptor threads
2020-04-07 15:59:42 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Starting
2020-04-07 15:59:42 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Starting
2020-04-07 15:59:42 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Starting
2020-04-07 15:59:42 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/0 (is it secure? false)
2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/0 is: OK
2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT))
2020-04-07 15:59:42 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7152749492694360216/meta.properties
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Starting
2020-04-07 15:59:42 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Starting
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] 0 successfully elected as the controller
2020-04-07 15:59:42 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Starting
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Reading controller epoch from ZooKeeper
2020-04-07 15:59:42 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Starting
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Incrementing controller epoch in ZooKeeper
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0001 type:setData cxid:0x21 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Epoch incremented to 1
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Registering handlers
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting log dir event notifications
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting isr change notifications
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing controller context
2020-04-07 15:59:42 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Starting up.
2020-04-07 15:59:42 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds.
2020-04-07 15:59:42 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Startup complete.
2020-04-07 15:59:42 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2020-04-07 15:59:42 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Starting up.
2020-04-07 15:59:42 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Starting
2020-04-07 15:59:42 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Startup complete.
2020-04-07 15:59:42 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions being reassigned: Map()
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently active brokers in the cluster: Set(0)
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently shutting brokers in the cluster: Set()
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Current list of topics in the cluster: Set()
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Fetching topic deletions in progress
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics to be deleted: 
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics ineligible for deletion: 
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing topic deletion manager
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Sending update metadata request
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Initializing replica state
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2020-04-07 15:59:42 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9092 (id: 0 rack: null) for sending state change requests
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Started replica state machine with initial state -> Map()
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Initializing partition state
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Triggering online partition state changes
2020-04-07 15:59:42 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Started partition state machine with initial state -> Map()
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Ready to serve as the new controller with epoch 1
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0001 type:delete cxid:0x33 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions undergoing preferred replica election: 
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions that completed preferred replica election: 
2020-04-07 15:59:42 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started processors for 1 acceptors
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Resuming preferred replica election for partitions: 
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting preferred replica leader election for partitions 
2020-04-07 15:59:42 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 15:59:42 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0001 type:delete cxid:0x39 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] started
2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2028772944758408940
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:59325
2020-04-07 15:59:42 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:59325.
2020-04-07 15:59:42 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59325 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6832f536
2020-04-07 15:59:42 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59325. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 15:59:42 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59335
2020-04-07 15:59:42 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59325, initiating session
2020-04-07 15:59:42 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59335
2020-04-07 15:59:42 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-04-07 15:59:42 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100035e711e0002 with negotiated timeout 6000 for client /127.0.0.1:59335
2020-04-07 15:59:42 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59325, sessionid = 0x100035e711e0002, negotiated timeout = 6000
2020-04-07 15:59:42 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0x1 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0x2 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-04-07 15:59:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting the controller scheduler
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0x3 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0x4 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0x5 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0x6 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0x7 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0x8 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0x9 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0xa zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0xb zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0xc zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-04-07 15:59:42 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:create cxid:0xd zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = nhrQJ8WvTD-t_j1Fn4aLZg
2020-04-07 15:59:42 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2028772944758408940/meta.properties
2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2028772944758408940
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:42 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2028772944758408940
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:42 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-04-07 15:59:42 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-04-07 15:59:42 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-04-07 15:59:42 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-04-07 15:59:42 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 0 ms.
2020-04-07 15:59:42 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-04-07 15:59:42 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-04-07 15:59:42 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-04-07 15:59:42 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9093.
2020-04-07 15:59:43 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started 1 acceptor threads
2020-04-07 15:59:43 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Starting
2020-04-07 15:59:43 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/1 (is it secure? false)
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/1 is: OK
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT))
2020-04-07 15:59:43 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2028772944758408940/meta.properties
2020-04-07 15:59:43 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Starting
2020-04-07 15:59:43 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 1, deleted brokers: , all live brokers: 0,1
2020-04-07 15:59:43 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Starting
2020-04-07 15:59:43 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Starting up.
2020-04-07 15:59:43 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 1
2020-04-07 15:59:43 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2020-04-07 15:59:43 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-04-07 15:59:43 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Startup complete.
2020-04-07 15:59:43 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2020-04-07 15:59:43 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Starting up.
2020-04-07 15:59:43 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Startup complete.
2020-04-07 15:59:43 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started processors for 1 acceptors
2020-04-07 15:59:43 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 15:59:43 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] started
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-496992175685025356
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:59325
2020-04-07 15:59:43 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:59325.
2020-04-07 15:59:43 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59325 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@310abad6
2020-04-07 15:59:43 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59325. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 15:59:43 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59325, initiating session
2020-04-07 15:59:43 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59337
2020-04-07 15:59:43 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59337
2020-04-07 15:59:43 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100035e711e0003 with negotiated timeout 6000 for client /127.0.0.1:59337
2020-04-07 15:59:43 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59325, sessionid = 0x100035e711e0003, negotiated timeout = 6000
2020-04-07 15:59:43 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-04-07 15:59:43 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x1 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x2 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x3 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x4 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x5 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x6 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x7 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x8 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x9 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0xa zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0xb zxid:0x3b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0xc zxid:0x3c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0xd zxid:0x3d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = nhrQJ8WvTD-t_j1Fn4aLZg
2020-04-07 15:59:43 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-496992175685025356/meta.properties
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-496992175685025356
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-496992175685025356
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:43 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-04-07 15:59:43 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-04-07 15:59:43 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 0 ms.
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-04-07 15:59:43 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9094.
2020-04-07 15:59:43 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started 1 acceptor threads
2020-04-07 15:59:43 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Starting
2020-04-07 15:59:43 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/2 (is it secure? false)
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/2 is: OK
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT))
2020-04-07 15:59:43 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-496992175685025356/meta.properties
2020-04-07 15:59:43 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Starting
2020-04-07 15:59:43 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 2, deleted brokers: , all live brokers: 0,1,2
2020-04-07 15:59:43 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Starting
2020-04-07 15:59:43 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-04-07 15:59:43 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 2
2020-04-07 15:59:43 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-04-07 15:59:43 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Starting up.
2020-04-07 15:59:43 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2020-04-07 15:59:43 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Startup complete.
2020-04-07 15:59:43 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2020-04-07 15:59:43 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Starting up.
2020-04-07 15:59:43 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Startup complete.
2020-04-07 15:59:43 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started processors for 1 acceptors
2020-04-07 15:59:43 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 15:59:43 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] started
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6714200143416712346
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:59325
2020-04-07 15:59:43 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:59325.
2020-04-07 15:59:43 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59325 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@332f6402
2020-04-07 15:59:43 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59325. Will not attempt to authenticate using SASL (unknown error)
2020-04-07 15:59:43 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59325, initiating session
2020-04-07 15:59:43 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59339
2020-04-07 15:59:43 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59339
2020-04-07 15:59:43 [Thread: main-SendThread(localhost:59325)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59325, sessionid = 0x100035e711e0004, negotiated timeout = 6000
2020-04-07 15:59:43 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100035e711e0004 with negotiated timeout 6000 for client /127.0.0.1:59339
2020-04-07 15:59:43 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-04-07 15:59:43 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x1 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x3 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x4 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x5 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x6 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x7 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x8 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x9 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0xa zxid:0x4a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0xb zxid:0x4b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0xc zxid:0x4c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-04-07 15:59:43 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0xd zxid:0x4d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = nhrQJ8WvTD-t_j1Fn4aLZg
2020-04-07 15:59:43 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6714200143416712346/meta.properties
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6714200143416712346
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6714200143416712346
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59325
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-04-07 15:59:43 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-04-07 15:59:43 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-04-07 15:59:43 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 1 ms.
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-04-07 15:59:43 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-04-07 15:59:43 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9095.
2020-04-07 15:59:43 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started 1 acceptor threads
2020-04-07 15:59:43 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Starting
2020-04-07 15:59:43 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/3 (is it secure? false)
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/3 is: OK
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT))
2020-04-07 15:59:43 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6714200143416712346/meta.properties
2020-04-07 15:59:43 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 3, deleted brokers: , all live brokers: 0,1,2,3
2020-04-07 15:59:43 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Starting
2020-04-07 15:59:43 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-04-07 15:59:43 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 3
2020-04-07 15:59:43 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-04-07 15:59:43 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Starting
2020-04-07 15:59:43 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Starting up.
2020-04-07 15:59:43 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds.
2020-04-07 15:59:43 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Startup complete.
2020-04-07 15:59:43 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4
2020-04-07 15:59:43 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Starting up.
2020-04-07 15:59:43 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Startup complete.
2020-04-07 15:59:43 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-04-07 15:59:43 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started processors for 1 acceptors
2020-04-07 15:59:43 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 15:59:43 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] started
2020-04-07 15:59:43 [Thread: main] [ INFO ] AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092, 127.0.0.1:9093, 127.0.0.1:9094, 127.0.0.1:9095]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-04-07 15:59:43 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-04-07 15:59:43 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-04-07 15:59:43 [Thread: kafka-admin-client-thread | adminclient-1] [ INFO ] AdminMetadataManager:238 - [AdminClient clientId=adminclient-1] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited.
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaTest:50 - Starting KafkaTest on 192.168.0.105 with PID 48511 (started by qianliqing in /Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer)
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaTest:675 - No active profile set, falling back to default profiles: default
2020-04-07 15:59:43 [Thread: main] [ INFO ] KafkaTest:59 - Started KafkaTest in 4.314 seconds (JVM running for 7.031)
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shutting down
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-04-07 15:59:44 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopping socket server request processors
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopped socket server request processors
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shutting down
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shut down completely
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] KafkaApis:66 - [KafkaApi-0] Shutdown complete.
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutting down
2020-04-07 15:59:44 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Stopped
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutdown completed
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutting down.
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 0]: Shutdown complete
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutting down
2020-04-07 15:59:44 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Stopped
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutdown completed
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutdown complete.
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutting down.
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutting down
2020-04-07 15:59:44 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Stopped
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutdown completed
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutting down
2020-04-07 15:59:44 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Stopped
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutdown completed
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutdown complete.
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shutting down
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-04-07 15:59:44 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutting down
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutdown completed
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutting down
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutting down
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutdown completed
2020-04-07 15:59:44 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Stopped
2020-04-07 15:59:44 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutting down
2020-04-07 15:59:45 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Stopped
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutdown completed
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutting down
2020-04-07 15:59:45 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Stopped
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shut down completely
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutting down.
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-04-07 15:59:45 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-04-07 15:59:45 [Thread: Thread-10] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7152749492694360216/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7152749492694360216/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutdown complete.
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutting down
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Stopped
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutdown completed
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Stopped partition state machine
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Stopped replica state machine
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-04-07 15:59:45 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-04-07 15:59:45 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-04-07 15:59:45 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-04-07 15:59:45 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] KafkaController:66 - [Controller id=0] Resigned
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-04-07 15:59:45 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100035e711e0001
2020-04-07 15:59:45 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100035e711e0001
2020-04-07 15:59:45 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59327 which had sessionid 0x100035e711e0001
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100035e711e0001 closed
2020-04-07 15:59:45 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100035e711e0001
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 15:59:45 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x25 zxid:0x52 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-04-07 15:59:45 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:create cxid:0x26 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] 1 successfully elected as the controller
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Reading controller epoch from ZooKeeper
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Initialized controller epoch to 1 and zk version 0
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Incrementing controller epoch in ZooKeeper
2020-04-07 15:59:45 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72061298197528578' does not match current session '72061298197528579'
2020-04-07 15:59:45 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72061298197528578' does not match current session '72061298197528580'
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Epoch incremented to 2
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Registering handlers
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Deleting log dir event notifications
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Deleting isr change notifications
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Initializing controller context
2020-04-07 15:59:45 [Thread: Controller-1-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Starting
2020-04-07 15:59:45 [Thread: Controller-1-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Starting
2020-04-07 15:59:45 [Thread: Controller-1-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Starting
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Partitions being reassigned: Map()
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Currently active brokers in the cluster: Set(1, 2, 3)
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Currently shutting brokers in the cluster: Set()
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Current list of topics in the cluster: Set()
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Fetching topic deletions in progress
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] List of topics to be deleted: 
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] List of topics ineligible for deletion: 
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Initializing topic deletion manager
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Sending update metadata request
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=1] Initializing replica state
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=1] Triggering online replica state changes
2020-04-07 15:59:45 [Thread: Controller-1-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Controller 1 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-04-07 15:59:45 [Thread: Controller-1-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Controller 1 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map()
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=1] Initializing partition state
2020-04-07 15:59:45 [Thread: Controller-1-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Controller 1 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=1] Triggering online partition state changes
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map()
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Ready to serve as the new controller with epoch 2
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-04-07 15:59:45 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:delete cxid:0x35 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Partitions undergoing preferred replica election: 
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Partitions that completed preferred replica election: 
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Skipping preferred replica election for partitions due to topic deletion: 
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Resuming preferred replica election for partitions: 
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Starting preferred replica leader election for partitions 
2020-04-07 15:59:45 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0002 type:delete cxid:0x37 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-04-07 15:59:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=1] Starting the controller scheduler
2020-04-07 15:59:45 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-04-07 15:59:45 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-04-07 15:59:46 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-04-07 15:59:46 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-04-07 15:59:46 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-04-07 15:59:47 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutting down socket server
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutdown completed
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shut down completed
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shutting down
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-04-07 15:59:47 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopping socket server request processors
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopped socket server request processors
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shutting down
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shut down completely
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] KafkaApis:66 - [KafkaApi-1] Shutdown complete.
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutting down
2020-04-07 15:59:47 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Stopped
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutdown completed
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutting down.
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 1]: Shutdown complete
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutting down
2020-04-07 15:59:47 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Stopped
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutdown completed
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutdown complete.
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutting down.
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutting down
2020-04-07 15:59:47 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Stopped
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2020-04-07 15:59:47 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutting down
2020-04-07 15:59:48 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutdown complete.
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shutting down
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-04-07 15:59:48 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutting down
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutting down
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutting down
2020-04-07 15:59:48 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutting down
2020-04-07 15:59:48 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2020-04-07 15:59:48 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shut down completely
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutting down.
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-04-07 15:59:48 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2028772944758408940/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2028772944758408940/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutdown complete.
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutting down
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Shutting down
2020-04-07 15:59:48 [Thread: Controller-1-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Shutting down
2020-04-07 15:59:48 [Thread: Controller-1-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Shutting down
2020-04-07 15:59:48 [Thread: Controller-1-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=1] Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] KafkaController:66 - [Controller id=1] Resigned
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-04-07 15:59:48 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100035e711e0002
2020-04-07 15:59:48 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100035e711e0002
2020-04-07 15:59:48 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59335 which had sessionid 0x100035e711e0002
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100035e711e0002 closed
2020-04-07 15:59:48 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100035e711e0002
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-04-07 15:59:48 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0003 type:create cxid:0x2d zxid:0x59 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] 3 successfully elected as the controller
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Reading controller epoch from ZooKeeper
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initialized controller epoch to 2 and zk version 1
2020-04-07 15:59:48 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72061298197528580' does not match current session '72061298197528579'
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Incrementing controller epoch in ZooKeeper
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Epoch incremented to 3
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Registering handlers
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting log dir event notifications
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting isr change notifications
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing controller context
2020-04-07 15:59:48 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-04-07 15:59:48 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions being reassigned: Map()
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently active brokers in the cluster: Set(2, 3)
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Current list of topics in the cluster: Set()
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Fetching topic deletions in progress
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics to be deleted: 
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics ineligible for deletion: 
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing topic deletion manager
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Sending update metadata request
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Initializing replica state
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Triggering online replica state changes
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Initializing partition state
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Triggering online partition state changes
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Ready to serve as the new controller with epoch 3
2020-04-07 15:59:48 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-04-07 15:59:48 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-04-07 15:59:48 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:delete cxid:0x3d zxid:0x5b txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions undergoing preferred replica election: 
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions that completed preferred replica election: 
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Resuming preferred replica election for partitions: 
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting preferred replica leader election for partitions 
2020-04-07 15:59:48 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100035e711e0004 type:delete cxid:0x3f zxid:0x5c txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-04-07 15:59:48 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting the controller scheduler
2020-04-07 15:59:48 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-04-07 15:59:48 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-04-07 15:59:49 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-04-07 15:59:49 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-04-07 15:59:49 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-04-07 15:59:50 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-04-07 15:59:50 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-04-07 15:59:50 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutting down socket server
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shut down completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shutting down
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-04-07 15:59:51 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopping socket server request processors
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopped socket server request processors
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shutting down
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shut down completely
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] KafkaApis:66 - [KafkaApi-2] Shutdown complete.
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutting down
2020-04-07 15:59:51 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Stopped
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutting down.
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 2000
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 2]: Shutdown complete
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutting down
2020-04-07 15:59:51 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Stopped
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutdown complete.
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutting down.
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutting down
2020-04-07 15:59:51 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Stopped
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutting down
2020-04-07 15:59:51 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Stopped
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutdown complete.
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shutting down
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-04-07 15:59:51 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutting down
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutting down
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutting down
2020-04-07 15:59:51 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Stopped
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutting down
2020-04-07 15:59:51 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Stopped
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutdown completed
2020-04-07 15:59:51 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2020-04-07 15:59:52 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Stopped
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shut down completely
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutting down.
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-04-07 15:59:52 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-04-07 15:59:52 [Thread: Thread-10] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-496992175685025356/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-496992175685025356/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutdown complete.
2020-04-07 15:59:52 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutting down
2020-04-07 15:59:52 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Stopped
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutdown completed
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] KafkaController:66 - [Controller id=2] Resigned
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-04-07 15:59:52 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100035e711e0003
2020-04-07 15:59:52 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100035e711e0003
2020-04-07 15:59:52 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59337 which had sessionid 0x100035e711e0003
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100035e711e0003 closed
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-04-07 15:59:52 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100035e711e0003
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-04-07 15:59:52 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Newly added brokers: , deleted brokers: 2, all live brokers: 3
2020-04-07 15:59:52 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-04-07 15:59:52 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-04-07 15:59:52 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-04-07 15:59:52 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Broker failure callback for 2
2020-04-07 15:59:52 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removed ArrayBuffer() from list of shutting down brokers.
2020-04-07 15:59:52 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-04-07 15:59:52 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-04-07 15:59:53 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-04-07 15:59:53 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-04-07 15:59:53 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-04-07 15:59:54 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutting down socket server
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shut down completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shutting down
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-04-07 15:59:54 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopping socket server request processors
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopped socket server request processors
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shutting down
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shut down completely
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] KafkaApis:66 - [KafkaApi-3] Shutdown complete.
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutting down
2020-04-07 15:59:54 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Stopped
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutting down.
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 3000
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 3]: Shutdown complete
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutting down
2020-04-07 15:59:54 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Stopped
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutdown complete.
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutting down.
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutting down
2020-04-07 15:59:54 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Stopped
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutting down
2020-04-07 15:59:54 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Stopped
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutdown complete.
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shutting down
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-04-07 15:59:54 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutting down
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutting down
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutting down
2020-04-07 15:59:54 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Stopped
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutdown completed
2020-04-07 15:59:54 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutting down
2020-04-07 15:59:55 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Stopped
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutdown completed
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2020-04-07 15:59:55 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Stopped
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shut down completely
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutting down.
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-04-07 15:59:55 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-04-07 15:59:55 [Thread: Thread-10] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6714200143416712346/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6714200143416712346/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] LogManager:66 - Shutdown complete.
2020-04-07 15:59:55 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutting down
2020-04-07 15:59:55 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Stopped
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutdown completed
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-04-07 15:59:55 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] KafkaController:66 - [Controller id=3] Resigned
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-04-07 15:59:55 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100035e711e0004
2020-04-07 15:59:55 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100035e711e0004
2020-04-07 15:59:55 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59339 which had sessionid 0x100035e711e0004
2020-04-07 15:59:55 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100035e711e0004
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100035e711e0004 closed
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-04-07 15:59:55 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-04-07 15:59:55 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-04-07 15:59:56 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-04-07 15:59:56 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutting down socket server
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutdown completed
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shut down completed
2020-04-07 15:59:56 [Thread: ZkClient-EventThread-20-127.0.0.1:59325] [ INFO ] ZkEventThread:83 - Terminate ZkClient event thread.
2020-04-07 15:59:56 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x100035e711e0000
2020-04-07 15:59:56 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x100035e711e0000
2020-04-07 15:59:56 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59326 which had sessionid 0x100035e711e0000
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] ZooKeeper:693 - Session: 0x100035e711e0000 closed
2020-04-07 15:59:56 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x100035e711e0000
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] ZooKeeperServer:502 - shutting down
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] SessionTrackerImpl:226 - Shutting down
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] PrepRequestProcessor:769 - Shutting down
2020-04-07 15:59:56 [Thread: ProcessThread(sid:0 cport:59325):] [ INFO ] PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] SyncRequestProcessor:208 - Shutting down
2020-04-07 15:59:56 [Thread: SyncThread:0] [ INFO ] SyncRequestProcessor:186 - SyncRequestProcessor exited!
2020-04-07 15:59:56 [Thread: Thread-10] [ INFO ] FinalRequestProcessor:403 - shutdown of request processor complete
2020-04-07 15:59:56 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
