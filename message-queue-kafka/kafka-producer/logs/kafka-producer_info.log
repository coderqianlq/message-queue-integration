2020-03-29 12:28:18 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:308 - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.qianlq.producer.kafka.KafkaTest], using SpringBootContextLoader
2020-03-29 12:28:18 [Thread: main] [ INFO ] AbstractContextLoader:264 - Could not detect default resource locations for test class [com.qianlq.producer.kafka.KafkaTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2020-03-29 12:28:18 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2020-03-29 12:28:18 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:177 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@793f29ff, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@3e8c3cb, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@563f38c4, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@543295b0, org.springframework.test.context.support.DirtiesContextTestExecutionListener@54422e18, org.springframework.test.context.transaction.TransactionalTestExecutionListener@117159c0, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3e27ba32, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@7ef82753, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@3b0fe47a, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@202b0582, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@235ecd9f, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@1ca3b418]
2020-03-29 12:28:19 [Thread: main] [ INFO ] Log4jControllerRegistration$:31 - Registered kafka:type=kafka.Log4jController MBean
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:host.name=192.168.0.104
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.version=1.8.0_161
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.vendor=Oracle Corporation
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.class.path=/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit-rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/tools.jar:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/Users/qianliqing/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.compiler=<NA>
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.name=Mac OS X
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.arch=x86_64
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.version=10.15.3
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.name=qianliqing
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.home=/Users/qianliqing
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperServer:174 - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7284963308590777730/version-2 snapdir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5299220159652910023/version-2
2020-03-29 12:28:20 [Thread: main] [ INFO ] NIOServerCnxnFactory:89 - binding to port /127.0.0.1:0
2020-03-29 12:28:20 [Thread: ZkClient-EventThread-21-127.0.0.1:53612] [ INFO ] ZkEventThread:65 - Starting ZkClient event thread.
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:host.name=192.168.0.104
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.version=1.8.0_161
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.class.path=/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit-rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/tools.jar:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/Users/qianliqing/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.compiler=<NA>
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.name=Mac OS X
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.arch=x86_64
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.version=10.15.3
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.name=qianliqing
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.home=/Users/qianliqing
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:53612 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@5c153b9e
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZkClient:936 - Waiting for keeper state SyncConnected
2020-03-29 12:28:20 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:53612. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 12:28:20 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:53612, initiating session
2020-03-29 12:28:20 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53613
2020-03-29 12:28:20 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:53613
2020-03-29 12:28:20 [Thread: SyncThread:0] [ INFO ] FileTxnLog:213 - Creating new log file: log.1
2020-03-29 12:28:20 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100024a6f170000 with negotiated timeout 6000 for client /127.0.0.1:53613
2020-03-29 12:28:20 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:53612, sessionid = 0x100024a6f170000, negotiated timeout = 6000
2020-03-29 12:28:20 [Thread: main-EventThread] [ INFO ] ZkClient:713 - zookeeper state changed (SyncConnected)
2020-03-29 12:28:20 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6230327741655139958
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:20 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 12:28:20 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:53612
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:53612.
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:53612 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5bd1ceca
2020-03-29 12:28:20 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:53612. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 12:28:20 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53618
2020-03-29 12:28:20 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:53612, initiating session
2020-03-29 12:28:20 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:53618
2020-03-29 12:28:20 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100024a6f170001 with negotiated timeout 6000 for client /127.0.0.1:53618
2020-03-29 12:28:20 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:53612, sessionid = 0x100024a6f170001, negotiated timeout = 6000
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 12:28:20 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 12:28:20 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2020-03-29 12:28:20 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2020-03-29 12:28:20 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2020-03-29 12:28:21 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2020-03-29 12:28:21 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = WjMlNZZ_St2o277EhTU6GQ
2020-03-29 12:28:21 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6230327741655139958/meta.properties
2020-03-29 12:28:21 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6230327741655139958
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:21 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6230327741655139958
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:21 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 12:28:21 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 12:28:21 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 12:28:21 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 12:28:21 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 11 ms.
2020-03-29 12:28:21 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 12:28:21 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 12:28:21 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 12:28:21 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 12:28:21 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9092.
2020-03-29 12:28:21 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started 1 acceptor threads
2020-03-29 12:28:21 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Starting
2020-03-29 12:28:21 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Starting
2020-03-29 12:28:21 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Starting
2020-03-29 12:28:21 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 12:28:21 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/0 (is it secure? false)
2020-03-29 12:28:21 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/0 is: OK
2020-03-29 12:28:21 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 12:28:21 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6230327741655139958/meta.properties
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Starting
2020-03-29 12:28:21 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Starting
2020-03-29 12:28:21 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Starting
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 12:28:21 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Starting
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] 0 successfully elected as the controller
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Reading controller epoch from ZooKeeper
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Incrementing controller epoch in ZooKeeper
2020-03-29 12:28:21 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170001 type:setData cxid:0x22 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Epoch incremented to 1
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Registering handlers
2020-03-29 12:28:21 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Starting up.
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting log dir event notifications
2020-03-29 12:28:21 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Startup complete.
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting isr change notifications
2020-03-29 12:28:21 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds.
2020-03-29 12:28:21 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing controller context
2020-03-29 12:28:21 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2020-03-29 12:28:22 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Starting up.
2020-03-29 12:28:22 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 12:28:22 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Starting
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions being reassigned: Map()
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently active brokers in the cluster: Set(0)
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently shutting brokers in the cluster: Set()
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Current list of topics in the cluster: Set()
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Fetching topic deletions in progress
2020-03-29 12:28:22 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Startup complete.
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics to be deleted: 
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics ineligible for deletion: 
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing topic deletion manager
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Sending update metadata request
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Initializing replica state
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Started replica state machine with initial state -> Map()
2020-03-29 12:28:22 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9092 (id: 0 rack: null) for sending state change requests
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Initializing partition state
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Triggering online partition state changes
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Started partition state machine with initial state -> Map()
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Ready to serve as the new controller with epoch 1
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170001 type:delete cxid:0x31 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions undergoing preferred replica election: 
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions that completed preferred replica election: 
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Resuming preferred replica election for partitions: 
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting preferred replica leader election for partitions 
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170001 type:delete cxid:0x33 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting the controller scheduler
2020-03-29 12:28:22 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started processors for 1 acceptors
2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] started
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:53612
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:53612.
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:53612 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5ff60a8c
2020-03-29 12:28:22 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:53612. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 12:28:22 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53624
2020-03-29 12:28:22 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:53612, initiating session
2020-03-29 12:28:22 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:53624
2020-03-29 12:28:22 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100024a6f170002 with negotiated timeout 6000 for client /127.0.0.1:53624
2020-03-29 12:28:22 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:53612, sessionid = 0x100024a6f170002, negotiated timeout = 6000
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0x1 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0x2 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0x3 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0x4 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0x5 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0x6 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0x7 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0x8 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0x9 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0xa zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0xb zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0xc zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170002 type:create cxid:0xd zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = WjMlNZZ_St2o277EhTU6GQ
2020-03-29 12:28:22 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074/meta.properties
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:22 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 12:28:22 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 12:28:22 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 0 ms.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 12:28:22 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9093.
2020-03-29 12:28:22 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started 1 acceptor threads
2020-03-29 12:28:22 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Starting
2020-03-29 12:28:22 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/1 (is it secure? false)
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/1 is: OK
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 12:28:22 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074/meta.properties
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Starting
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 1, deleted brokers: , all live brokers: 0,1
2020-03-29 12:28:22 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Starting
2020-03-29 12:28:22 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 1
2020-03-29 12:28:22 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-03-29 12:28:22 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Starting up.
2020-03-29 12:28:22 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 12:28:22 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Startup complete.
2020-03-29 12:28:22 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2020-03-29 12:28:22 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Starting up.
2020-03-29 12:28:22 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Startup complete.
2020-03-29 12:28:22 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started processors for 1 acceptors
2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] started
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5159073110515642880
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:53612
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:53612.
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:53612 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@38eb2c50
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 12:28:22 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:53612. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 12:28:22 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:53612, initiating session
2020-03-29 12:28:22 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53626
2020-03-29 12:28:22 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:53626
2020-03-29 12:28:22 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100024a6f170003 with negotiated timeout 6000 for client /127.0.0.1:53626
2020-03-29 12:28:22 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:53612, sessionid = 0x100024a6f170003, negotiated timeout = 6000
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0x1 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0x2 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0x3 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0x4 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0x5 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0x6 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0x7 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0x8 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0x9 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0xa zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0xb zxid:0x3b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0xc zxid:0x3c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170003 type:create cxid:0xd zxid:0x3d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = WjMlNZZ_St2o277EhTU6GQ
2020-03-29 12:28:22 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5159073110515642880/meta.properties
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5159073110515642880
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5159073110515642880
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:22 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 12:28:22 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 12:28:22 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 1 ms.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 12:28:22 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9094.
2020-03-29 12:28:22 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started 1 acceptor threads
2020-03-29 12:28:22 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Starting
2020-03-29 12:28:22 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/2 (is it secure? false)
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/2 is: OK
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 12:28:22 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5159073110515642880/meta.properties
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Starting
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 2, deleted brokers: , all live brokers: 0,1,2
2020-03-29 12:28:22 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Starting
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 2
2020-03-29 12:28:22 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 12:28:22 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-03-29 12:28:22 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Starting up.
2020-03-29 12:28:22 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 12:28:22 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Startup complete.
2020-03-29 12:28:22 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2020-03-29 12:28:22 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Starting up.
2020-03-29 12:28:22 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Startup complete.
2020-03-29 12:28:22 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Starting
2020-03-29 12:28:22 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started processors for 1 acceptors
2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] started
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5824753676926043257
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:53612
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:53612.
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:53612 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3506d826
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 12:28:22 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:53612. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 12:28:22 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:53628
2020-03-29 12:28:22 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:53612, initiating session
2020-03-29 12:28:22 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:53628
2020-03-29 12:28:22 [Thread: main-SendThread(localhost:53612)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:53612, sessionid = 0x100024a6f170004, negotiated timeout = 6000
2020-03-29 12:28:22 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x100024a6f170004 with negotiated timeout 6000 for client /127.0.0.1:53628
2020-03-29 12:28:22 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0x1 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0x2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0x3 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0x4 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0x5 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0x6 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0x7 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0x8 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0x9 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0xa zxid:0x4a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0xb zxid:0x4b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0xc zxid:0x4c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 12:28:22 [Thread: ProcessThread(sid:0 cport:53612):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x100024a6f170004 type:create cxid:0xd zxid:0x4d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = WjMlNZZ_St2o277EhTU6GQ
2020-03-29 12:28:22 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5824753676926043257/meta.properties
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5824753676926043257
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5824753676926043257
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:53612
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 12:28:22 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 12:28:22 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 12:28:22 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 0 ms.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 12:28:22 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 12:28:22 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9095.
2020-03-29 12:28:22 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started 1 acceptor threads
2020-03-29 12:28:22 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Starting
2020-03-29 12:28:22 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/3 (is it secure? false)
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/3 is: OK
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 3, deleted brokers: , all live brokers: 0,1,2,3
2020-03-29 12:28:22 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-5824753676926043257/meta.properties
2020-03-29 12:28:22 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 3
2020-03-29 12:28:22 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-03-29 12:28:22 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Starting
2020-03-29 12:28:22 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Starting up.
2020-03-29 12:28:22 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Startup complete.
2020-03-29 12:28:22 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds.
2020-03-29 12:28:22 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4
2020-03-29 12:28:22 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Starting up.
2020-03-29 12:28:22 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Startup complete.
2020-03-29 12:28:22 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 12:28:22 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started processors for 1 acceptors
2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] started
2020-03-29 12:28:22 [Thread: main] [ INFO ] AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092, 127.0.0.1:9093, 127.0.0.1:9094, 127.0.0.1:9095]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 12:28:22 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 12:28:22 [Thread: kafka-admin-client-thread | adminclient-1] [ INFO ] AdminMetadataManager:238 - [AdminClient clientId=adminclient-1] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: Timed out waiting to send the call.
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaTest:50 - Starting KafkaTest on 192.168.0.104 with PID 11118 (started by qianliqing in /Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer)
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaTest:675 - No active profile set, falling back to default profiles: default
2020-03-29 12:28:22 [Thread: main] [ INFO ] KafkaTest:59 - Started KafkaTest in 4.013 seconds (JVM running for 6.087)
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shutting down
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 12:30:21 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopping socket server request processors
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopped socket server request processors
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shutting down
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shut down completely
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] KafkaApis:66 - [KafkaApi-0] Shutdown complete.
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutting down
2020-03-29 12:30:21 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Stopped
2020-03-29 12:30:21 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutdown completed
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutting down.
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 0]: Shutdown complete
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutting down
2020-03-29 12:30:22 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Stopped
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutdown completed
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutdown complete.
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutting down.
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutting down
2020-03-29 12:30:22 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Stopped
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutdown completed
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutting down
2020-03-29 12:30:22 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Stopped
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutdown completed
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutdown complete.
2020-03-29 12:30:22 [Thread: kafka-log-cleaner-thread-0] [ ERROR] LogDirFailureChannel:76 - Error while reading checkpoint file /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074/cleaner-offset-checkpoint
java.io.FileNotFoundException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074/cleaner-offset-checkpoint (No such file or directory)
	at java.io.FileInputStream.open0(Native Method) ~[?:1.8.0_161]
	at java.io.FileInputStream.open(FileInputStream.java:195) ~[?:1.8.0_161]
	at java.io.FileInputStream.<init>(FileInputStream.java:138) ~[?:1.8.0_161]
	at kafka.server.checkpoints.CheckpointFile.liftedTree2$1(CheckpointFile.scala:87) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.checkpoints.CheckpointFile.read(CheckpointFile.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.checkpoints.OffsetCheckpointFile.read(OffsetCheckpointFile.scala:61) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$allCleanerCheckpoints$1$$anonfun$apply$1.apply(LogCleanerManager.scala:89) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$allCleanerCheckpoints$1$$anonfun$apply$1.apply(LogCleanerManager.scala:87) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241) [scala-library-2.11.12.jar:?]
	at scala.collection.Iterator$class.foreach(Iterator.scala:891) [scala-library-2.11.12.jar:?]
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) [scala-library-2.11.12.jar:?]
	at scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:206) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241) [scala-library-2.11.12.jar:?]
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104) [scala-library-2.11.12.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$allCleanerCheckpoints$1.apply(LogCleanerManager.scala:87) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$allCleanerCheckpoints$1.apply(LogCleanerManager.scala:95) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager.allCleanerCheckpoints(LogCleanerManager.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$grabFilthiestCompactedLog$1.apply(LogCleanerManager.scala:126) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$grabFilthiestCompactedLog$1.apply(LogCleanerManager.scala:123) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager.grabFilthiestCompactedLog(LogCleanerManager.scala:123) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:296) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:289) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82) [kafka_2.11-2.0.1.jar:?]
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shutting down
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 12:30:22 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 12:30:22 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Stopping serving replicas in dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutting down
2020-03-29 12:30:22 [Thread: kafka-log-cleaner-thread-0] [ ERROR] LogCleaner:76 - Failed to access checkpoint file cleaner-offset-checkpoint in dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074
org.apache.kafka.common.errors.KafkaStorageException: Error while reading checkpoint file /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074/cleaner-offset-checkpoint
Caused by: java.io.FileNotFoundException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074/cleaner-offset-checkpoint (No such file or directory)
	at java.io.FileInputStream.open0(Native Method) ~[?:1.8.0_161]
	at java.io.FileInputStream.open(FileInputStream.java:195) ~[?:1.8.0_161]
	at java.io.FileInputStream.<init>(FileInputStream.java:138) ~[?:1.8.0_161]
	at kafka.server.checkpoints.CheckpointFile.liftedTree2$1(CheckpointFile.scala:87) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.server.checkpoints.CheckpointFile.read(CheckpointFile.scala:86) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.server.checkpoints.OffsetCheckpointFile.read(OffsetCheckpointFile.scala:61) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$allCleanerCheckpoints$1$$anonfun$apply$1.apply(LogCleanerManager.scala:89) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$allCleanerCheckpoints$1$$anonfun$apply$1.apply(LogCleanerManager.scala:87) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241) [scala-library-2.11.12.jar:?]
	at scala.collection.Iterator$class.foreach(Iterator.scala:891) [scala-library-2.11.12.jar:?]
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) [scala-library-2.11.12.jar:?]
	at scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:206) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241) [scala-library-2.11.12.jar:?]
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104) [scala-library-2.11.12.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$allCleanerCheckpoints$1.apply(LogCleanerManager.scala:87) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$allCleanerCheckpoints$1.apply(LogCleanerManager.scala:95) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager.allCleanerCheckpoints(LogCleanerManager.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$grabFilthiestCompactedLog$1.apply(LogCleanerManager.scala:126) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager$$anonfun$grabFilthiestCompactedLog$1.apply(LogCleanerManager.scala:123) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleanerManager.grabFilthiestCompactedLog(LogCleanerManager.scala:123) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:296) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:289) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82) [kafka_2.11-2.0.1.jar:?]
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutdown completed
2020-03-29 12:30:22 [Thread: LogDirFailureHandler] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] Removed fetcher for partitions 
2020-03-29 12:30:22 [Thread: LogDirFailureHandler] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions 
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutting down
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2020-03-29 12:30:22 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutting down
2020-03-29 12:30:22 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074.
2020-03-29 12:30:22 [Thread: LogDirFailureHandler] [ INFO ] LogManager:66 - Stopping serving logs in dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074
2020-03-29 12:30:22 [Thread: LogDirFailureHandler] [ ERROR] LogManager:79 - Shutdown broker because all log dirs in /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1381261757473608074 have failed
2020-03-29 14:56:33 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:308 - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.qianlq.producer.kafka.KafkaTest], using SpringBootContextLoader
2020-03-29 14:56:33 [Thread: main] [ INFO ] AbstractContextLoader:264 - Could not detect default resource locations for test class [com.qianlq.producer.kafka.KafkaTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2020-03-29 14:56:33 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2020-03-29 14:56:33 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:177 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@3e27ba32, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ef82753, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@3b0fe47a, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@202b0582, org.springframework.test.context.support.DirtiesContextTestExecutionListener@235ecd9f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@1ca3b418, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58cbafc2, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@2034b64c, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@75d3a5e0, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@74d1dc36, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@7161d8d1, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@74e28667]
2020-03-29 14:56:33 [Thread: main] [ INFO ] Log4jControllerRegistration$:31 - Registered kafka:type=kafka.Log4jController MBean
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:host.name=192.168.0.104
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.version=1.8.0_161
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.vendor=Oracle Corporation
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.class.path=/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit-rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/tools.jar:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/Users/qianliqing/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.compiler=<NA>
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.name=Mac OS X
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.arch=x86_64
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.version=10.15.3
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.name=qianliqing
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.home=/Users/qianliqing
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperServer:174 - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2731053245695469693/version-2 snapdir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-7581069519837929218/version-2
2020-03-29 14:56:34 [Thread: main] [ INFO ] NIOServerCnxnFactory:89 - binding to port /127.0.0.1:0
2020-03-29 14:56:34 [Thread: ZkClient-EventThread-21-127.0.0.1:58437] [ INFO ] ZkEventThread:65 - Starting ZkClient event thread.
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:host.name=192.168.0.104
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.version=1.8.0_161
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.class.path=/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit-rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/tools.jar:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/Users/qianliqing/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.compiler=<NA>
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.name=Mac OS X
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.arch=x86_64
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.version=10.15.3
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.name=qianliqing
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.home=/Users/qianliqing
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:58437 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@758a34ce
2020-03-29 14:56:34 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:58437. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZkClient:936 - Waiting for keeper state SyncConnected
2020-03-29 14:56:34 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:58437, initiating session
2020-03-29 14:56:34 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:58438
2020-03-29 14:56:34 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:58438
2020-03-29 14:56:34 [Thread: SyncThread:0] [ INFO ] FileTxnLog:213 - Creating new log file: log.1
2020-03-29 14:56:34 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002ccb0e80000 with negotiated timeout 6000 for client /127.0.0.1:58438
2020-03-29 14:56:34 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:58437, sessionid = 0x10002ccb0e80000, negotiated timeout = 6000
2020-03-29 14:56:34 [Thread: main-EventThread] [ INFO ] ZkClient:713 - zookeeper state changed (SyncConnected)
2020-03-29 14:56:34 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6831779408485945743
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:34 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 14:56:34 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:58437
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:58437.
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:58437 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@499b2a5c
2020-03-29 14:56:34 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:58437. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 14:56:34 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:58437, initiating session
2020-03-29 14:56:34 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:58439
2020-03-29 14:56:34 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:58439
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 14:56:34 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:58437, sessionid = 0x10002ccb0e80001, negotiated timeout = 6000
2020-03-29 14:56:34 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002ccb0e80001 with negotiated timeout 6000 for client /127.0.0.1:58439
2020-03-29 14:56:34 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 14:56:34 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2020-03-29 14:56:34 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2020-03-29 14:56:34 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2020-03-29 14:56:34 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2020-03-29 14:56:34 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = 6i2QMSlwRgKErQJ6iC34lA
2020-03-29 14:56:34 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6831779408485945743/meta.properties
2020-03-29 14:56:34 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6831779408485945743
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:34 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6831779408485945743
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:34 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 14:56:34 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 14:56:34 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 14:56:34 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 14:56:34 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 7 ms.
2020-03-29 14:56:34 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 14:56:34 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 14:56:34 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 14:56:34 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9092.
2020-03-29 14:56:35 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started 1 acceptor threads
2020-03-29 14:56:35 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Starting
2020-03-29 14:56:35 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/0 (is it secure? false)
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/0 is: OK
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 14:56:35 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6831779408485945743/meta.properties
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Starting
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 14:56:35 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Starting
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] 0 successfully elected as the controller
2020-03-29 14:56:35 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Starting
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Reading controller epoch from ZooKeeper
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Incrementing controller epoch in ZooKeeper
2020-03-29 14:56:35 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Starting
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80001 type:setData cxid:0x21 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Epoch incremented to 1
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Registering handlers
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting log dir event notifications
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting isr change notifications
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing controller context
2020-03-29 14:56:35 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Starting up.
2020-03-29 14:56:35 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Startup complete.
2020-03-29 14:56:35 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds.
2020-03-29 14:56:35 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2020-03-29 14:56:35 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Starting up.
2020-03-29 14:56:35 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Startup complete.
2020-03-29 14:56:35 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions being reassigned: Map()
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently active brokers in the cluster: Set(0)
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently shutting brokers in the cluster: Set()
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Current list of topics in the cluster: Set()
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Fetching topic deletions in progress
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics to be deleted: 
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics ineligible for deletion: 
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing topic deletion manager
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Sending update metadata request
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Initializing replica state
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Started replica state machine with initial state -> Map()
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Initializing partition state
2020-03-29 14:56:35 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9092 (id: 0 rack: null) for sending state change requests
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Triggering online partition state changes
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Started partition state machine with initial state -> Map()
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Ready to serve as the new controller with epoch 1
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80001 type:delete cxid:0x31 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-03-29 14:56:35 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions undergoing preferred replica election: 
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions that completed preferred replica election: 
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Resuming preferred replica election for partitions: 
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting preferred replica leader election for partitions 
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80001 type:delete cxid:0x38 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting the controller scheduler
2020-03-29 14:56:35 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started processors for 1 acceptors
2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] started
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8055646323639733140
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:58437
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:58437.
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:58437 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@889d9e8
2020-03-29 14:56:35 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:58437. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 14:56:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:58444
2020-03-29 14:56:35 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:58437, initiating session
2020-03-29 14:56:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:58444
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 14:56:35 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002ccb0e80002 with negotiated timeout 6000 for client /127.0.0.1:58444
2020-03-29 14:56:35 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:58437, sessionid = 0x10002ccb0e80002, negotiated timeout = 6000
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x1 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x2 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x3 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x4 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x5 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x6 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x7 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x8 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x9 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0xa zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0xb zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0xc zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0xd zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = 6i2QMSlwRgKErQJ6iC34lA
2020-03-29 14:56:35 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8055646323639733140/meta.properties
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8055646323639733140
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8055646323639733140
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:35 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 14:56:35 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 14:56:35 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 1 ms.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 14:56:35 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9093.
2020-03-29 14:56:35 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started 1 acceptor threads
2020-03-29 14:56:35 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Starting
2020-03-29 14:56:35 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/1 (is it secure? false)
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/1 is: OK
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 14:56:35 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8055646323639733140/meta.properties
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Starting
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 1, deleted brokers: , all live brokers: 0,1
2020-03-29 14:56:35 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Starting
2020-03-29 14:56:35 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 1
2020-03-29 14:56:35 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Starting
2020-03-29 14:56:35 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-03-29 14:56:35 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Starting up.
2020-03-29 14:56:35 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Startup complete.
2020-03-29 14:56:35 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 14:56:35 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2020-03-29 14:56:35 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Starting up.
2020-03-29 14:56:35 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Startup complete.
2020-03-29 14:56:35 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started processors for 1 acceptors
2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] started
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2508390031673553086
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:58437
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:58437.
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:58437 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@10ee04df
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 14:56:35 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:58437. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 14:56:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:58446
2020-03-29 14:56:35 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:58437, initiating session
2020-03-29 14:56:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:58446
2020-03-29 14:56:35 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002ccb0e80003 with negotiated timeout 6000 for client /127.0.0.1:58446
2020-03-29 14:56:35 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:58437, sessionid = 0x10002ccb0e80003, negotiated timeout = 6000
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x1 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x2 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x3 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x4 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x5 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x6 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x7 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x8 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x9 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0xa zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0xb zxid:0x3b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0xc zxid:0x3c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0xd zxid:0x3d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = 6i2QMSlwRgKErQJ6iC34lA
2020-03-29 14:56:35 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2508390031673553086/meta.properties
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2508390031673553086
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2508390031673553086
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:35 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 14:56:35 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 14:56:35 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 1 ms.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 14:56:35 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9094.
2020-03-29 14:56:35 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started 1 acceptor threads
2020-03-29 14:56:35 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Starting
2020-03-29 14:56:35 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/2 (is it secure? false)
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 2, deleted brokers: , all live brokers: 0,1,2
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/2 is: OK
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 14:56:35 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 2
2020-03-29 14:56:35 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-2508390031673553086/meta.properties
2020-03-29 14:56:35 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Starting up.
2020-03-29 14:56:35 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Startup complete.
2020-03-29 14:56:35 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 14:56:35 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2020-03-29 14:56:35 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Starting up.
2020-03-29 14:56:35 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Startup complete.
2020-03-29 14:56:35 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started processors for 1 acceptors
2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] started
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4018189220179721988
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:58437
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:58437.
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:58437 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@363f0ba0
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 14:56:35 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:58437. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 14:56:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:58448
2020-03-29 14:56:35 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:58437, initiating session
2020-03-29 14:56:35 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:58448
2020-03-29 14:56:35 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002ccb0e80004 with negotiated timeout 6000 for client /127.0.0.1:58448
2020-03-29 14:56:35 [Thread: main-SendThread(localhost:58437)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:58437, sessionid = 0x10002ccb0e80004, negotiated timeout = 6000
2020-03-29 14:56:35 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0x1 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0x2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0x3 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0x4 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0x5 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0x6 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0x7 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0x8 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0x9 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0xa zxid:0x4a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0xb zxid:0x4b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0xc zxid:0x4c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 14:56:35 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:create cxid:0xd zxid:0x4d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = 6i2QMSlwRgKErQJ6iC34lA
2020-03-29 14:56:35 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4018189220179721988/meta.properties
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4018189220179721988
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4018189220179721988
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:58437
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 14:56:35 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 14:56:35 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 14:56:35 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 0 ms.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 14:56:35 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 14:56:35 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9095.
2020-03-29 14:56:35 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started 1 acceptor threads
2020-03-29 14:56:35 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Starting
2020-03-29 14:56:35 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/3 (is it secure? false)
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/3 is: OK
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 14:56:35 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4018189220179721988/meta.properties
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 3, deleted brokers: , all live brokers: 0,1,2,3
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 3
2020-03-29 14:56:35 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 14:56:35 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-03-29 14:56:35 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Starting
2020-03-29 14:56:35 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Starting up.
2020-03-29 14:56:35 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 14:56:35 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Startup complete.
2020-03-29 14:56:35 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4
2020-03-29 14:56:35 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Starting up.
2020-03-29 14:56:35 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Startup complete.
2020-03-29 14:56:35 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 14:56:35 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started processors for 1 acceptors
2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] started
2020-03-29 14:56:35 [Thread: main] [ INFO ] AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092, 127.0.0.1:9093, 127.0.0.1:9094, 127.0.0.1:9095]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 14:56:35 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 14:56:35 [Thread: kafka-admin-client-thread | adminclient-1] [ INFO ] AdminMetadataManager:238 - [AdminClient clientId=adminclient-1] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: Timed out waiting to send the call.
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaTest:50 - Starting KafkaTest on 192.168.0.104 with PID 12596 (started by qianliqing in /Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer)
2020-03-29 14:56:35 [Thread: main] [ INFO ] KafkaTest:675 - No active profile set, falling back to default profiles: default
2020-03-29 14:56:36 [Thread: main] [ WARN ] GenericWebApplicationContext:557 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'kafkaTest': Unsatisfied dependency expressed through field 'kafkaTemplate'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
2020-03-29 14:56:36 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shutting down
2020-03-29 14:56:36 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 14:56:36 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopping socket server request processors
2020-03-29 14:56:36 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopped socket server request processors
2020-03-29 14:56:36 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shutting down
2020-03-29 14:56:36 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shut down completely
2020-03-29 14:56:36 [Thread: main] [ INFO ] KafkaApis:66 - [KafkaApi-0] Shutdown complete.
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutting down
2020-03-29 14:56:36 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutting down.
2020-03-29 14:56:36 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2020-03-29 14:56:36 [Thread: main] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 0]: Shutdown complete
2020-03-29 14:56:36 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutting down
2020-03-29 14:56:36 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutdown complete.
2020-03-29 14:56:36 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutting down.
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutting down
2020-03-29 14:56:36 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutting down
2020-03-29 14:56:36 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutdown complete.
2020-03-29 14:56:36 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shutting down
2020-03-29 14:56:36 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 14:56:36 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutting down
2020-03-29 14:56:36 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutting down
2020-03-29 14:56:36 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutting down
2020-03-29 14:56:36 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutting down
2020-03-29 14:56:36 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutting down
2020-03-29 14:56:36 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shut down completely
2020-03-29 14:56:36 [Thread: main] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 14:56:36 [Thread: main] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 14:56:36 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 14:56:36 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutting down
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Stopped partition state machine
2020-03-29 14:56:36 [Thread: main] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Stopped replica state machine
2020-03-29 14:56:36 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 14:56:36 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 14:56:36 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 14:56:36 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 14:56:36 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] KafkaController:66 - [Controller id=0] Resigned
2020-03-29 14:56:36 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 14:56:36 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002ccb0e80001
2020-03-29 14:56:36 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002ccb0e80001
2020-03-29 14:56:36 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:58439 which had sessionid 0x10002ccb0e80001
2020-03-29 14:56:36 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002ccb0e80001
2020-03-29 14:56:36 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002ccb0e80001 closed
2020-03-29 14:56:36 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 14:56:36 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80002 type:create cxid:0x24 zxid:0x52 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-03-29 14:56:36 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80003 type:create cxid:0x25 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] 3 successfully elected as the controller
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Reading controller epoch from ZooKeeper
2020-03-29 14:56:36 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 14:56:36 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72060672202506244' does not match current session '72060672202506243'
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-03-29 14:56:36 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72060672202506244' does not match current session '72060672202506242'
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initialized controller epoch to 1 and zk version 0
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Incrementing controller epoch in ZooKeeper
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Epoch incremented to 2
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Registering handlers
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting log dir event notifications
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting isr change notifications
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing controller context
2020-03-29 14:56:36 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-03-29 14:56:36 [Thread: Controller-3-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-03-29 14:56:36 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions being reassigned: Map()
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently active brokers in the cluster: Set(1, 2, 3)
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Current list of topics in the cluster: Set()
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Fetching topic deletions in progress
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics to be deleted: 
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics ineligible for deletion: 
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing topic deletion manager
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Sending update metadata request
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Initializing replica state
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Triggering online replica state changes
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Initializing partition state
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Triggering online partition state changes
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Ready to serve as the new controller with epoch 2
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-03-29 14:56:36 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-03-29 14:56:36 [Thread: Controller-3-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-03-29 14:56:36 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-03-29 14:56:36 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:delete cxid:0x37 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions undergoing preferred replica election: 
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions that completed preferred replica election: 
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Resuming preferred replica election for partitions: 
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting preferred replica leader election for partitions 
2020-03-29 14:56:36 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002ccb0e80004 type:delete cxid:0x39 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-03-29 14:56:36 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting the controller scheduler
2020-03-29 14:56:36 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 14:56:36 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 14:56:36 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 14:56:37 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 14:56:37 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 14:56:37 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 14:56:37 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 14:56:37 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 14:56:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutting down socket server
2020-03-29 14:56:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutdown completed
2020-03-29 14:56:37 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shut down completed
2020-03-29 14:56:37 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shutting down
2020-03-29 14:56:37 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 14:56:37 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 14:56:37 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 14:56:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopping socket server request processors
2020-03-29 14:56:37 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopped socket server request processors
2020-03-29 14:56:37 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shutting down
2020-03-29 14:56:37 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shut down completely
2020-03-29 14:56:37 [Thread: main] [ INFO ] KafkaApis:66 - [KafkaApi-1] Shutdown complete.
2020-03-29 14:56:37 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutting down
2020-03-29 14:56:38 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Stopped
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutdown completed
2020-03-29 14:56:38 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutting down.
2020-03-29 14:56:38 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000
2020-03-29 14:56:38 [Thread: main] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 1]: Shutdown complete
2020-03-29 14:56:38 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutting down
2020-03-29 14:56:38 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Stopped
2020-03-29 14:56:38 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutdown completed
2020-03-29 14:56:38 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutdown complete.
2020-03-29 14:56:38 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutting down.
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutting down
2020-03-29 14:56:38 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Stopped
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutting down
2020-03-29 14:56:38 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Stopped
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2020-03-29 14:56:38 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutdown complete.
2020-03-29 14:56:38 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shutting down
2020-03-29 14:56:38 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 14:56:38 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 14:56:38 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 14:56:38 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutting down
2020-03-29 14:56:38 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutdown completed
2020-03-29 14:56:38 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutting down
2020-03-29 14:56:38 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutting down
2020-03-29 14:56:38 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Stopped
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutdown completed
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutting down
2020-03-29 14:56:38 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Stopped
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutdown completed
2020-03-29 14:56:38 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2020-03-29 14:56:39 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Stopped
2020-03-29 14:56:39 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2020-03-29 14:56:39 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shut down completely
2020-03-29 14:56:39 [Thread: main] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 14:56:39 [Thread: main] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 14:56:39 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 14:56:39 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 14:56:39 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 14:56:39 [Thread: main] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 14:56:39 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutting down
2020-03-29 14:56:39 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Stopped
2020-03-29 14:56:39 [Thread: main] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutdown completed
2020-03-29 14:56:39 [Thread: main] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2020-03-29 14:56:39 [Thread: main] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2020-03-29 14:56:39 [Thread: main] [ INFO ] KafkaController:66 - [Controller id=1] Resigned
2020-03-29 14:56:39 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 14:56:39 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002ccb0e80002
2020-03-29 14:56:39 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002ccb0e80002
2020-03-29 14:56:39 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002ccb0e80002 closed
2020-03-29 14:56:39 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:58444 which had sessionid 0x10002ccb0e80002
2020-03-29 14:56:39 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002ccb0e80002
2020-03-29 14:56:39 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 14:56:39 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 14:56:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Newly added brokers: , deleted brokers: 1, all live brokers: 2,3
2020-03-29 14:56:39 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-03-29 14:56:39 [Thread: Controller-3-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-03-29 14:56:39 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-03-29 14:56:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Broker failure callback for 1
2020-03-29 14:56:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removed ArrayBuffer() from list of shutting down brokers.
2020-03-29 14:56:39 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 14:56:39 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 14:56:39 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 14:56:40 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 14:56:40 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 14:56:40 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 14:56:41 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 14:56:41 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 14:56:41 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutting down socket server
2020-03-29 14:56:41 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutdown completed
2020-03-29 14:56:41 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shut down completed
2020-03-29 14:56:41 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shutting down
2020-03-29 14:56:41 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 14:56:41 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 14:56:41 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 14:56:41 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopping socket server request processors
2020-03-29 14:56:41 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopped socket server request processors
2020-03-29 14:56:41 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shutting down
2020-03-29 14:56:41 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shut down completely
2020-03-29 14:56:41 [Thread: main] [ INFO ] KafkaApis:66 - [KafkaApi-2] Shutdown complete.
2020-03-29 14:56:41 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutting down
2020-03-29 14:56:41 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Stopped
2020-03-29 14:56:41 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutdown completed
2020-03-29 14:56:41 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutting down.
2020-03-29 14:56:41 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 2000
2020-03-29 14:56:41 [Thread: main] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 2]: Shutdown complete
2020-03-29 14:56:41 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutting down
2020-03-29 14:56:41 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Stopped
2020-03-29 14:56:41 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutdown completed
2020-03-29 14:56:41 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutdown complete.
2020-03-29 14:56:41 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutting down.
2020-03-29 14:56:41 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutting down
2020-03-29 14:56:41 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Stopped
2020-03-29 14:56:41 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2020-03-29 14:56:41 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutting down
2020-03-29 14:56:42 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Stopped
2020-03-29 14:56:42 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutdown complete.
2020-03-29 14:56:42 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shutting down
2020-03-29 14:56:42 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 14:56:42 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 14:56:42 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutting down
2020-03-29 14:56:42 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutting down
2020-03-29 14:56:42 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutting down
2020-03-29 14:56:42 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Stopped
2020-03-29 14:56:42 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutting down
2020-03-29 14:56:42 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Stopped
2020-03-29 14:56:42 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2020-03-29 14:56:42 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Stopped
2020-03-29 14:56:42 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shut down completely
2020-03-29 14:56:42 [Thread: main] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 14:56:42 [Thread: main] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 14:56:42 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 14:56:42 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 14:56:42 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 14:56:42 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutting down
2020-03-29 14:56:42 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Stopped
2020-03-29 14:56:42 [Thread: main] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2020-03-29 14:56:42 [Thread: main] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2020-03-29 14:56:42 [Thread: main] [ INFO ] KafkaController:66 - [Controller id=2] Resigned
2020-03-29 14:56:42 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 14:56:42 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002ccb0e80003
2020-03-29 14:56:42 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002ccb0e80003
2020-03-29 14:56:42 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:58446 which had sessionid 0x10002ccb0e80003
2020-03-29 14:56:42 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002ccb0e80003 closed
2020-03-29 14:56:42 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002ccb0e80003
2020-03-29 14:56:42 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 14:56:42 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 14:56:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Newly added brokers: , deleted brokers: 2, all live brokers: 3
2020-03-29 14:56:42 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-03-29 14:56:42 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-03-29 14:56:42 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-03-29 14:56:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Broker failure callback for 2
2020-03-29 14:56:42 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removed ArrayBuffer() from list of shutting down brokers.
2020-03-29 14:56:42 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 14:56:42 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 14:56:42 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 14:56:43 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 14:56:43 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 14:56:43 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 14:56:44 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 14:56:44 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 14:56:44 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutting down socket server
2020-03-29 14:56:44 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutdown completed
2020-03-29 14:56:44 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shut down completed
2020-03-29 14:56:44 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shutting down
2020-03-29 14:56:44 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 14:56:44 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 14:56:44 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 14:56:44 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopping socket server request processors
2020-03-29 14:56:44 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopped socket server request processors
2020-03-29 14:56:44 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shutting down
2020-03-29 14:56:44 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shut down completely
2020-03-29 14:56:44 [Thread: main] [ INFO ] KafkaApis:66 - [KafkaApi-3] Shutdown complete.
2020-03-29 14:56:44 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutting down
2020-03-29 14:56:44 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Stopped
2020-03-29 14:56:44 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutdown completed
2020-03-29 14:56:44 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutting down.
2020-03-29 14:56:44 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 3000
2020-03-29 14:56:44 [Thread: main] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 3]: Shutdown complete
2020-03-29 14:56:44 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutting down
2020-03-29 14:56:44 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Stopped
2020-03-29 14:56:44 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutdown completed
2020-03-29 14:56:44 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutdown complete.
2020-03-29 14:56:44 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutting down.
2020-03-29 14:56:44 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutting down
2020-03-29 14:56:44 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Stopped
2020-03-29 14:56:44 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2020-03-29 14:56:44 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutting down
2020-03-29 14:56:45 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Stopped
2020-03-29 14:56:45 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutdown complete.
2020-03-29 14:56:45 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shutting down
2020-03-29 14:56:45 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 14:56:45 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 14:56:45 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutting down
2020-03-29 14:56:45 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutting down
2020-03-29 14:56:45 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutting down
2020-03-29 14:56:45 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Stopped
2020-03-29 14:56:45 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutting down
2020-03-29 14:56:45 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Stopped
2020-03-29 14:56:45 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2020-03-29 14:56:45 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Stopped
2020-03-29 14:56:45 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shut down completely
2020-03-29 14:56:45 [Thread: main] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 14:56:45 [Thread: main] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 14:56:45 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 14:56:45 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 14:56:45 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 14:56:45 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutting down
2020-03-29 14:56:45 [Thread: main] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutdown completed
2020-03-29 14:56:45 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Stopped
2020-03-29 14:56:45 [Thread: main] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2020-03-29 14:56:45 [Thread: main] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2020-03-29 14:56:45 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-03-29 14:56:45 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-03-29 14:56:45 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] KafkaController:66 - [Controller id=3] Resigned
2020-03-29 14:56:45 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 14:56:45 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002ccb0e80004
2020-03-29 14:56:45 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002ccb0e80004
2020-03-29 14:56:45 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002ccb0e80004
2020-03-29 14:56:45 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:58448 which had sessionid 0x10002ccb0e80004
2020-03-29 14:56:45 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002ccb0e80004 closed
2020-03-29 14:56:45 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 14:56:45 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 14:56:45 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 14:56:45 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 14:56:45 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 14:56:46 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 14:56:46 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 14:56:46 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 14:56:47 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 14:56:47 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 14:56:47 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutting down socket server
2020-03-29 14:56:47 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutdown completed
2020-03-29 14:56:47 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shut down completed
2020-03-29 14:56:47 [Thread: ZkClient-EventThread-21-127.0.0.1:58437] [ INFO ] ZkEventThread:83 - Terminate ZkClient event thread.
2020-03-29 14:56:47 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002ccb0e80000
2020-03-29 14:56:47 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002ccb0e80000
2020-03-29 14:56:47 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:58438 which had sessionid 0x10002ccb0e80000
2020-03-29 14:56:47 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002ccb0e80000
2020-03-29 14:56:47 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002ccb0e80000 closed
2020-03-29 14:56:47 [Thread: main] [ INFO ] ZooKeeperServer:502 - shutting down
2020-03-29 14:56:47 [Thread: main] [ INFO ] SessionTrackerImpl:226 - Shutting down
2020-03-29 14:56:47 [Thread: main] [ INFO ] PrepRequestProcessor:769 - Shutting down
2020-03-29 14:56:47 [Thread: ProcessThread(sid:0 cport:58437):] [ INFO ] PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2020-03-29 14:56:47 [Thread: main] [ INFO ] SyncRequestProcessor:208 - Shutting down
2020-03-29 14:56:47 [Thread: SyncThread:0] [ INFO ] SyncRequestProcessor:186 - SyncRequestProcessor exited!
2020-03-29 14:56:47 [Thread: main] [ INFO ] FinalRequestProcessor:403 - shutdown of request processor complete
2020-03-29 14:56:47 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2020-03-29 14:56:47 [Thread: main] [ ERROR] LoggingFailureAnalysisReporter:42 - 

***************************
APPLICATION FAILED TO START
***************************

Description:

Field kafkaTemplate in com.qianlq.producer.kafka.KafkaTest required a bean of type 'org.springframework.kafka.core.KafkaTemplate' that could not be found.

The injection point has the following annotations:
	- @org.springframework.beans.factory.annotation.Autowired(required=true)


Action:

Consider defining a bean of type 'org.springframework.kafka.core.KafkaTemplate' in your configuration.

2020-03-29 14:56:47 [Thread: main] [ ERROR] TestContextManager:250 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@3e27ba32] to prepare test instance [com.qianlq.producer.kafka.KafkaTest@3e104d4b]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:125) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) [junit-rt.jar:?]
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) [junit-rt.jar:?]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) [junit-rt.jar:?]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) [junit-rt.jar:?]
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'kafkaTest': Unsatisfied dependency expressed through field 'kafkaTemplate'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:843) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	... 24 more
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1655) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1214) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1168) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:843) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	... 24 more
2020-03-29 15:03:37 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:308 - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.qianlq.producer.kafka.KafkaTest], using SpringBootContextLoader
2020-03-29 15:03:37 [Thread: main] [ INFO ] AbstractContextLoader:264 - Could not detect default resource locations for test class [com.qianlq.producer.kafka.KafkaTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2020-03-29 15:03:37 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2020-03-29 15:03:37 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:177 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@3e8c3cb, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@563f38c4, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@543295b0, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@54422e18, org.springframework.test.context.support.DirtiesContextTestExecutionListener@117159c0, org.springframework.test.context.transaction.TransactionalTestExecutionListener@3e27ba32, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@7ef82753, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@3b0fe47a, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@202b0582, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@235ecd9f, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@1ca3b418, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@58cbafc2]
2020-03-29 15:03:38 [Thread: main] [ INFO ] Log4jControllerRegistration$:31 - Registered kafka:type=kafka.Log4jController MBean
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:host.name=192.168.0.104
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.version=1.8.0_161
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.vendor=Oracle Corporation
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.class.path=/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit-rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/tools.jar:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/Users/qianliqing/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.compiler=<NA>
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.name=Mac OS X
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.arch=x86_64
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.version=10.15.3
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.name=qianliqing
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.home=/Users/qianliqing
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeperServer:174 - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4256581696597652918/version-2 snapdir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8260016336290734264/version-2
2020-03-29 15:03:38 [Thread: main] [ INFO ] NIOServerCnxnFactory:89 - binding to port /127.0.0.1:0
2020-03-29 15:03:38 [Thread: ZkClient-EventThread-21-127.0.0.1:59553] [ INFO ] ZkEventThread:65 - Starting ZkClient event thread.
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:host.name=192.168.0.104
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.version=1.8.0_161
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.class.path=/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit-rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/tools.jar:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/Users/qianliqing/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.compiler=<NA>
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.name=Mac OS X
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.arch=x86_64
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.version=10.15.3
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.name=qianliqing
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.home=/Users/qianliqing
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59553 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@1d0d6318
2020-03-29 15:03:38 [Thread: main] [ INFO ] ZkClient:936 - Waiting for keeper state SyncConnected
2020-03-29 15:03:38 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59553. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:03:38 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59553, initiating session
2020-03-29 15:03:38 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59554
2020-03-29 15:03:38 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59554
2020-03-29 15:03:38 [Thread: SyncThread:0] [ INFO ] FileTxnLog:213 - Creating new log file: log.1
2020-03-29 15:03:38 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d32b680000 with negotiated timeout 6000 for client /127.0.0.1:59554
2020-03-29 15:03:38 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59553, sessionid = 0x10002d32b680000, negotiated timeout = 6000
2020-03-29 15:03:38 [Thread: main-EventThread] [ INFO ] ZkClient:713 - zookeeper state changed (SyncConnected)
2020-03-29 15:03:39 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8834745306878295158
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:39 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 15:03:39 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:59553
2020-03-29 15:03:39 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:59553.
2020-03-29 15:03:39 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59553 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@57f791c6
2020-03-29 15:03:39 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59553. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:03:39 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59553, initiating session
2020-03-29 15:03:39 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59555
2020-03-29 15:03:39 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59555
2020-03-29 15:03:39 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 15:03:39 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d32b680001 with negotiated timeout 6000 for client /127.0.0.1:59555
2020-03-29 15:03:39 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59553, sessionid = 0x10002d32b680001, negotiated timeout = 6000
2020-03-29 15:03:39 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 15:03:39 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2020-03-29 15:03:39 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2020-03-29 15:03:39 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2020-03-29 15:03:39 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2020-03-29 15:03:39 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = Gd7gHk11Q1e9gLHH7dMl9w
2020-03-29 15:03:39 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8834745306878295158/meta.properties
2020-03-29 15:03:39 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8834745306878295158
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:39 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8834745306878295158
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:39 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 15:03:39 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 15:03:39 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 15:03:39 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 15:03:39 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 8 ms.
2020-03-29 15:03:39 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 15:03:39 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 15:03:39 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 15:03:39 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 15:03:39 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9092.
2020-03-29 15:03:39 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started 1 acceptor threads
2020-03-29 15:03:39 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Starting
2020-03-29 15:03:39 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Starting
2020-03-29 15:03:39 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Starting
2020-03-29 15:03:39 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 15:03:39 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/0 (is it secure? false)
2020-03-29 15:03:39 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/0 is: OK
2020-03-29 15:03:39 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 15:03:39 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8834745306878295158/meta.properties
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Starting
2020-03-29 15:03:39 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Starting
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] 0 successfully elected as the controller
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Reading controller epoch from ZooKeeper
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Incrementing controller epoch in ZooKeeper
2020-03-29 15:03:39 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Starting
2020-03-29 15:03:39 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Starting
2020-03-29 15:03:39 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680001 type:setData cxid:0x21 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Epoch incremented to 1
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Registering handlers
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting log dir event notifications
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting isr change notifications
2020-03-29 15:03:39 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing controller context
2020-03-29 15:03:39 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Starting up.
2020-03-29 15:03:39 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds.
2020-03-29 15:03:39 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Startup complete.
2020-03-29 15:03:39 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2020-03-29 15:03:40 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions being reassigned: Map()
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently active brokers in the cluster: Set(0)
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently shutting brokers in the cluster: Set()
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Current list of topics in the cluster: Set()
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Fetching topic deletions in progress
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics to be deleted: 
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics ineligible for deletion: 
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing topic deletion manager
2020-03-29 15:03:40 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Starting up.
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Sending update metadata request
2020-03-29 15:03:40 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Startup complete.
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Initializing replica state
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2020-03-29 15:03:40 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9092 (id: 0 rack: null) for sending state change requests
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Started replica state machine with initial state -> Map()
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Initializing partition state
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Triggering online partition state changes
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Started partition state machine with initial state -> Map()
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Ready to serve as the new controller with epoch 1
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680001 type:delete cxid:0x31 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions undergoing preferred replica election: 
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions that completed preferred replica election: 
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Resuming preferred replica election for partitions: 
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting preferred replica leader election for partitions 
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680001 type:delete cxid:0x33 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting the controller scheduler
2020-03-29 15:03:40 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started processors for 1 acceptors
2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] started
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-554353193033163112
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:59553
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:59553.
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59553 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5cbd159f
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 15:03:40 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59553. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:03:40 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59553, initiating session
2020-03-29 15:03:40 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59560
2020-03-29 15:03:40 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59560
2020-03-29 15:03:40 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d32b680002 with negotiated timeout 6000 for client /127.0.0.1:59560
2020-03-29 15:03:40 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59553, sessionid = 0x10002d32b680002, negotiated timeout = 6000
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x1 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x2 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x3 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x4 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x5 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x6 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x7 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x8 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x9 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0xa zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0xb zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0xc zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0xd zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = Gd7gHk11Q1e9gLHH7dMl9w
2020-03-29 15:03:40 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-554353193033163112/meta.properties
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-554353193033163112
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-554353193033163112
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:40 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 15:03:40 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 15:03:40 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 0 ms.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 15:03:40 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9093.
2020-03-29 15:03:40 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started 1 acceptor threads
2020-03-29 15:03:40 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Starting
2020-03-29 15:03:40 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/1 (is it secure? false)
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/1 is: OK
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 15:03:40 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-554353193033163112/meta.properties
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 1, deleted brokers: , all live brokers: 0,1
2020-03-29 15:03:40 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 1
2020-03-29 15:03:40 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Starting up.
2020-03-29 15:03:40 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Startup complete.
2020-03-29 15:03:40 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 15:03:40 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2020-03-29 15:03:40 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Starting up.
2020-03-29 15:03:40 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Startup complete.
2020-03-29 15:03:40 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started processors for 1 acceptors
2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] started
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4892789514270784070
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:59553
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:59553.
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59553 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5e2f3be5
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 15:03:40 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59553. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:03:40 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59562
2020-03-29 15:03:40 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59553, initiating session
2020-03-29 15:03:40 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59562
2020-03-29 15:03:40 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d32b680003 with negotiated timeout 6000 for client /127.0.0.1:59562
2020-03-29 15:03:40 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59553, sessionid = 0x10002d32b680003, negotiated timeout = 6000
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x1 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x2 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x3 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x4 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x5 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x6 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x7 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x8 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x9 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0xa zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0xb zxid:0x3b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0xc zxid:0x3c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0xd zxid:0x3d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = Gd7gHk11Q1e9gLHH7dMl9w
2020-03-29 15:03:40 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4892789514270784070/meta.properties
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4892789514270784070
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4892789514270784070
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:40 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 15:03:40 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 15:03:40 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 1 ms.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 15:03:40 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9094.
2020-03-29 15:03:40 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started 1 acceptor threads
2020-03-29 15:03:40 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Starting
2020-03-29 15:03:40 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/2 (is it secure? false)
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/2 is: OK
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 15:03:40 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4892789514270784070/meta.properties
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 2, deleted brokers: , all live brokers: 0,1,2
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Starting
2020-03-29 15:03:40 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 2
2020-03-29 15:03:40 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-03-29 15:03:40 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Starting up.
2020-03-29 15:03:40 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 15:03:40 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Startup complete.
2020-03-29 15:03:40 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2020-03-29 15:03:40 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Starting up.
2020-03-29 15:03:40 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Startup complete.
2020-03-29 15:03:40 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started processors for 1 acceptors
2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] started
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3727556271637017733
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:59553
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:59553.
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:59553 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5782d777
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 15:03:40 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:59553. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:03:40 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:59553, initiating session
2020-03-29 15:03:40 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:59564
2020-03-29 15:03:40 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:59564
2020-03-29 15:03:40 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d32b680004 with negotiated timeout 6000 for client /127.0.0.1:59564
2020-03-29 15:03:40 [Thread: main-SendThread(localhost:59553)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:59553, sessionid = 0x10002d32b680004, negotiated timeout = 6000
2020-03-29 15:03:40 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0x1 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0x2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0x3 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0x4 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0x5 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0x6 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0x7 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0x8 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0x9 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0xa zxid:0x4a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0xb zxid:0x4b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0xc zxid:0x4c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 15:03:40 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:create cxid:0xd zxid:0x4d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = Gd7gHk11Q1e9gLHH7dMl9w
2020-03-29 15:03:40 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3727556271637017733/meta.properties
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3727556271637017733
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3727556271637017733
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59553
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:03:40 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 15:03:40 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 15:03:40 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 2 ms.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 15:03:40 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 15:03:40 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9095.
2020-03-29 15:03:40 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started 1 acceptor threads
2020-03-29 15:03:40 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Starting
2020-03-29 15:03:40 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/3 (is it secure? false)
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/3 is: OK
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 3, deleted brokers: , all live brokers: 0,1,2,3
2020-03-29 15:03:40 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3727556271637017733/meta.properties
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 3
2020-03-29 15:03:40 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 15:03:40 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Starting
2020-03-29 15:03:40 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-03-29 15:03:40 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Starting
2020-03-29 15:03:40 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Starting up.
2020-03-29 15:03:40 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 15:03:40 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Startup complete.
2020-03-29 15:03:40 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4
2020-03-29 15:03:40 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Starting up.
2020-03-29 15:03:40 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Startup complete.
2020-03-29 15:03:40 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 15:03:40 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started processors for 1 acceptors
2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] started
2020-03-29 15:03:40 [Thread: main] [ INFO ] AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092, 127.0.0.1:9093, 127.0.0.1:9094, 127.0.0.1:9095]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:03:40 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:03:40 [Thread: kafka-admin-client-thread | adminclient-1] [ INFO ] AdminMetadataManager:238 - [AdminClient clientId=adminclient-1] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: Timed out waiting to send the call.
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaTest:50 - Starting KafkaTest on 192.168.0.104 with PID 12679 (started by qianliqing in /Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer)
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaTest:675 - No active profile set, falling back to default profiles: default
2020-03-29 15:03:40 [Thread: main] [ INFO ] KafkaTest:59 - Started KafkaTest in 2.764 seconds (JVM running for 4.326)
2020-03-29 15:03:40 [Thread: Thread-9] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shutting down
2020-03-29 15:03:40 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 15:03:40 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 15:03:40 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 15:03:40 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopping socket server request processors
2020-03-29 15:03:40 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopped socket server request processors
2020-03-29 15:03:40 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shutting down
2020-03-29 15:03:40 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shut down completely
2020-03-29 15:03:40 [Thread: Thread-9] [ INFO ] KafkaApis:66 - [KafkaApi-0] Shutdown complete.
2020-03-29 15:03:40 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutting down
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutdown completed
2020-03-29 15:03:41 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutting down.
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 0]: Shutdown complete
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutting down
2020-03-29 15:03:41 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutdown complete.
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutting down.
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutting down
2020-03-29 15:03:41 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutting down
2020-03-29 15:03:41 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutdown complete.
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shutting down
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 15:03:41 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutting down
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutting down
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutting down
2020-03-29 15:03:41 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutting down
2020-03-29 15:03:41 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutting down
2020-03-29 15:03:41 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shut down completely
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 15:03:41 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8834745306878295158/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-8834745306878295158/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutting down
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutdown completed
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Stopped partition state machine
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Stopped replica state machine
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 15:03:41 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 15:03:41 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 15:03:41 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 15:03:41 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] KafkaController:66 - [Controller id=0] Resigned
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 15:03:41 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d32b680001
2020-03-29 15:03:41 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d32b680001
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ZooKeeper:693 - Session: 0x10002d32b680001 closed
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 15:03:41 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 15:03:41 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59555 which had sessionid 0x10002d32b680001
2020-03-29 15:03:41 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d32b680001
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 15:03:41 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680003 type:create cxid:0x25 zxid:0x52 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-03-29 15:03:41 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680002 type:create cxid:0x24 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] 3 successfully elected as the controller
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Reading controller epoch from ZooKeeper
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initialized controller epoch to 1 and zk version 0
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Incrementing controller epoch in ZooKeeper
2020-03-29 15:03:41 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72060700027518980' does not match current session '72060700027518978'
2020-03-29 15:03:41 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72060700027518980' does not match current session '72060700027518979'
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Epoch incremented to 2
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Registering handlers
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting log dir event notifications
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting isr change notifications
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing controller context
2020-03-29 15:03:41 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-03-29 15:03:41 [Thread: Controller-3-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-03-29 15:03:41 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions being reassigned: Map()
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently active brokers in the cluster: Set(1, 2, 3)
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Current list of topics in the cluster: Set()
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Fetching topic deletions in progress
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics to be deleted: 
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics ineligible for deletion: 
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing topic deletion manager
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Sending update metadata request
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Initializing replica state
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Triggering online replica state changes
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Initializing partition state
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Triggering online partition state changes
2020-03-29 15:03:41 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-03-29 15:03:41 [Thread: Controller-3-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-03-29 15:03:41 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Ready to serve as the new controller with epoch 2
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-03-29 15:03:41 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:delete cxid:0x37 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions undergoing preferred replica election: 
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions that completed preferred replica election: 
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Resuming preferred replica election for partitions: 
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting preferred replica leader election for partitions 
2020-03-29 15:03:41 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d32b680004 type:delete cxid:0x39 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-03-29 15:03:41 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting the controller scheduler
2020-03-29 15:03:42 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 15:03:42 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 15:03:42 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 15:03:43 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 15:03:43 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 15:03:43 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 15:03:44 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutting down socket server
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutdown completed
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shut down completed
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shutting down
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopping socket server request processors
2020-03-29 15:03:44 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopped socket server request processors
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shutting down
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shut down completely
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] KafkaApis:66 - [KafkaApi-1] Shutdown complete.
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutting down
2020-03-29 15:03:44 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Stopped
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutdown completed
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutting down.
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 1]: Shutdown complete
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutting down
2020-03-29 15:03:44 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Stopped
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutdown completed
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutdown complete.
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutting down.
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutting down
2020-03-29 15:03:44 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Stopped
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2020-03-29 15:03:44 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutting down
2020-03-29 15:03:45 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Stopped
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutdown complete.
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shutting down
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 15:03:45 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutting down
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutdown completed
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutting down
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutting down
2020-03-29 15:03:45 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Stopped
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutdown completed
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutting down
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutdown completed
2020-03-29 15:03:45 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Stopped
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2020-03-29 15:03:45 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Stopped
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shut down completely
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 15:03:45 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 15:03:45 [Thread: Thread-9] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-554353193033163112/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-554353193033163112/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 15:03:45 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutting down
2020-03-29 15:03:45 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Stopped
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutdown completed
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] KafkaController:66 - [Controller id=1] Resigned
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 15:03:45 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d32b680002
2020-03-29 15:03:45 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d32b680002
2020-03-29 15:03:45 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59560 which had sessionid 0x10002d32b680002
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ZooKeeper:693 - Session: 0x10002d32b680002 closed
2020-03-29 15:03:45 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d32b680002
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 15:03:45 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 15:03:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Newly added brokers: , deleted brokers: 1, all live brokers: 2,3
2020-03-29 15:03:45 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-03-29 15:03:45 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-03-29 15:03:45 [Thread: Controller-3-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-03-29 15:03:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Broker failure callback for 1
2020-03-29 15:03:45 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removed ArrayBuffer() from list of shutting down brokers.
2020-03-29 15:03:46 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 15:03:46 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 15:03:46 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 15:03:47 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 15:03:47 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 15:03:47 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 15:03:48 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutting down socket server
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shut down completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shutting down
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 15:03:48 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopping socket server request processors
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopped socket server request processors
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shutting down
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shut down completely
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] KafkaApis:66 - [KafkaApi-2] Shutdown complete.
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutting down
2020-03-29 15:03:48 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Stopped
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutting down.
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 2000
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 2]: Shutdown complete
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutting down
2020-03-29 15:03:48 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Stopped
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutdown complete.
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutting down.
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutting down
2020-03-29 15:03:48 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Stopped
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutting down
2020-03-29 15:03:48 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Stopped
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutdown complete.
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shutting down
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 15:03:48 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutting down
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutting down
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutting down
2020-03-29 15:03:48 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Stopped
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutdown completed
2020-03-29 15:03:48 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutting down
2020-03-29 15:03:49 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Stopped
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutdown completed
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2020-03-29 15:03:49 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Stopped
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shut down completely
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 15:03:49 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 15:03:49 [Thread: Thread-9] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4892789514270784070/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4892789514270784070/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 15:03:49 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutting down
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutdown completed
2020-03-29 15:03:49 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Stopped
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] KafkaController:66 - [Controller id=2] Resigned
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 15:03:49 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d32b680003
2020-03-29 15:03:49 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d32b680003
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] ZooKeeper:693 - Session: 0x10002d32b680003 closed
2020-03-29 15:03:49 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d32b680003
2020-03-29 15:03:49 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59562 which had sessionid 0x10002d32b680003
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 15:03:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Newly added brokers: , deleted brokers: 2, all live brokers: 3
2020-03-29 15:03:49 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-03-29 15:03:49 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-03-29 15:03:49 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-03-29 15:03:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Broker failure callback for 2
2020-03-29 15:03:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removed ArrayBuffer() from list of shutting down brokers.
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 15:03:49 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 15:03:49 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 15:03:50 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 15:03:50 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 15:03:50 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 15:03:51 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutting down socket server
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shut down completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shutting down
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopping socket server request processors
2020-03-29 15:03:51 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopped socket server request processors
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shutting down
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shut down completely
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] KafkaApis:66 - [KafkaApi-3] Shutdown complete.
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutting down
2020-03-29 15:03:51 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Stopped
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutting down.
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 3000
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 3]: Shutdown complete
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutting down
2020-03-29 15:03:51 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Stopped
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutdown complete.
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutting down.
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutting down
2020-03-29 15:03:51 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Stopped
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutting down
2020-03-29 15:03:51 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Stopped
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutdown complete.
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shutting down
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 15:03:51 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutting down
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutting down
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutdown completed
2020-03-29 15:03:51 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutting down
2020-03-29 15:03:52 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Stopped
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutdown completed
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutting down
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutdown completed
2020-03-29 15:03:52 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Stopped
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2020-03-29 15:03:52 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Stopped
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shut down completely
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 15:03:52 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 15:03:52 [Thread: Thread-9] [ WARN ] CoreUtils$:90 - /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3727556271637017733/.kafka_cleanshutdown
java.nio.file.NoSuchFileException: /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3727556271637017733/.kafka_cleanshutdown
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:1.8.0_161]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:1.8.0_161]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:1.8.0_161]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_161]
	at java.nio.file.Files.createFile(Files.java:632) ~[?:1.8.0_161]
	at kafka.log.LogManager$$anonfun$shutdown$6$$anonfun$apply$4.apply$mcV$sp(LogManager.scala:476) ~[kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:476) [kafka_2.11-2.0.1.jar:?]
	at kafka.log.LogManager$$anonfun$shutdown$6.apply(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40) [scala-library-2.11.12.jar:?]
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:130) [scala-library-2.11.12.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) [scala-library-2.11.12.jar:?]
	at kafka.log.LogManager.shutdown(LogManager.scala:464) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer$$anonfun$shutdown$13.apply$mcV$sp(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86) [kafka_2.11-2.0.1.jar:?]
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:598) [kafka_2.11-2.0.1.jar:?]
	at org.springframework.kafka.test.EmbeddedKafkaBroker.destroy(EmbeddedKafkaBroker.java:327) [spring-kafka-test-2.2.6.RELEASE.jar:2.2.6.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:571) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:543) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1034) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:504) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1027) [spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1057) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1026) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:945) [spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 15:03:52 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutting down
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutdown completed
2020-03-29 15:03:52 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Stopped
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-03-29 15:03:52 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] KafkaController:66 - [Controller id=3] Resigned
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 15:03:52 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d32b680004
2020-03-29 15:03:52 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d32b680004
2020-03-29 15:03:52 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59564 which had sessionid 0x10002d32b680004
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] ZooKeeper:693 - Session: 0x10002d32b680004 closed
2020-03-29 15:03:52 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d32b680004
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 15:03:52 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 15:03:52 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 15:03:53 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 15:03:53 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 15:03:53 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 15:03:54 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutting down socket server
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutdown completed
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shut down completed
2020-03-29 15:03:54 [Thread: ZkClient-EventThread-21-127.0.0.1:59553] [ INFO ] ZkEventThread:83 - Terminate ZkClient event thread.
2020-03-29 15:03:54 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d32b680000
2020-03-29 15:03:54 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d32b680000
2020-03-29 15:03:54 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:59554 which had sessionid 0x10002d32b680000
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] ZooKeeper:693 - Session: 0x10002d32b680000 closed
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] ZooKeeperServer:502 - shutting down
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] SessionTrackerImpl:226 - Shutting down
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] PrepRequestProcessor:769 - Shutting down
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] SyncRequestProcessor:208 - Shutting down
2020-03-29 15:03:54 [Thread: ProcessThread(sid:0 cport:59553):] [ INFO ] PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2020-03-29 15:03:54 [Thread: SyncThread:0] [ INFO ] SyncRequestProcessor:186 - SyncRequestProcessor exited!
2020-03-29 15:03:54 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d32b680000
2020-03-29 15:03:54 [Thread: Thread-9] [ INFO ] FinalRequestProcessor:403 - shutdown of request processor complete
2020-03-29 15:03:54 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2020-03-29 15:08:47 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:308 - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.qianlq.producer.kafka.KafkaTest], using SpringBootContextLoader
2020-03-29 15:08:47 [Thread: main] [ INFO ] AbstractContextLoader:264 - Could not detect default resource locations for test class [com.qianlq.producer.kafka.KafkaTest]: no resource found for suffixes {-context.xml, Context.groovy}.
2020-03-29 15:08:47 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:248 - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
2020-03-29 15:08:47 [Thread: main] [ INFO ] SpringBootTestContextBootstrapper:177 - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@3e27ba32, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@7ef82753, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@3b0fe47a, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@202b0582, org.springframework.test.context.support.DirtiesContextTestExecutionListener@235ecd9f, org.springframework.test.context.transaction.TransactionalTestExecutionListener@1ca3b418, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@58cbafc2, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@2034b64c, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@75d3a5e0, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@74d1dc36, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@7161d8d1, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@74e28667]
2020-03-29 15:08:48 [Thread: main] [ INFO ] Log4jControllerRegistration$:31 - Registered kafka:type=kafka.Log4jController MBean
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:host.name=192.168.0.104
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.version=1.8.0_161
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.vendor=Oracle Corporation
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.class.path=/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit-rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/tools.jar:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/Users/qianliqing/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:java.compiler=<NA>
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.name=Mac OS X
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.arch=x86_64
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:os.version=10.15.3
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.name=qianliqing
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.home=/Users/qianliqing
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:100 - Server environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeperServer:174 - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-4276549646947220197/version-2 snapdir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1380969961466622623/version-2
2020-03-29 15:08:48 [Thread: main] [ INFO ] NIOServerCnxnFactory:89 - binding to port /127.0.0.1:0
2020-03-29 15:08:48 [Thread: ZkClient-EventThread-21-127.0.0.1:60479] [ INFO ] ZkEventThread:65 - Starting ZkClient event thread.
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:host.name=192.168.0.104
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.version=1.8.0_161
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.class.path=/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit-rt.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/junit/lib/junit5-rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/tools.jar:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/test-classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer/target/classes:/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-core/target/classes:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.5.RELEASE/spring-boot-starter-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot/2.1.5.RELEASE/spring-boot-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.5.RELEASE/spring-boot-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-core/5.1.7.RELEASE/spring-core-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-jcl/5.1.7.RELEASE/spring-jcl-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.4.RELEASE/spring-boot-starter-web-2.1.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.5.RELEASE/spring-boot-starter-json-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.8/jackson-databind-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.5.RELEASE/spring-boot-starter-tomcat-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.19/tomcat-embed-core-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.19/tomcat-embed-el-9.0.19.jar:/Users/qianliqing/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.19/tomcat-embed-websocket-9.0.19.jar:/Users/qianliqing/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.16.Final/hibernate-validator-6.0.16.Final.jar:/Users/qianliqing/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/Users/qianliqing/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-web/5.1.7.RELEASE/spring-web-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-beans/5.1.7.RELEASE/spring-beans-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-webmvc/5.1.7.RELEASE/spring-webmvc-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-aop/5.1.7.RELEASE/spring-aop-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-expression/5.1.7.RELEASE/spring-expression-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.5.RELEASE/spring-boot-starter-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test/2.1.5.RELEASE/spring-boot-test-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.5.RELEASE/spring-boot-test-autoconfigure-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/Users/qianliqing/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/qianliqing/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/qianliqing/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/qianliqing/.m2/repository/junit/junit/4.12/junit-4.12.jar:/Users/qianliqing/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/Users/qianliqing/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy/1.9.12/byte-buddy-1.9.12.jar:/Users/qianliqing/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.12/byte-buddy-agent-1.9.12.jar:/Users/qianliqing/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/qianliqing/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/Users/qianliqing/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/Users/qianliqing/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-test/5.1.7.RELEASE/spring-test-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/xmlunit/xmlunit-core/2.6.2/xmlunit-core-2.6.2.jar:/Users/qianliqing/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/Users/qianliqing/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/Users/qianliqing/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.5.RELEASE/spring-boot-starter-log4j2-2.1.5.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar:/Users/qianliqing/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar:/Users/qianliqing/.m2/repository/org/slf4j/jul-to-slf4j/1.7.26/jul-to-slf4j-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka/2.2.6.RELEASE/spring-kafka-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-context/5.1.7.RELEASE/spring-context-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-messaging/5.1.7.RELEASE/spring-messaging-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/spring-tx/5.1.7.RELEASE/spring-tx-5.1.7.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/Users/qianliqing/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/Users/qianliqing/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/Users/qianliqing/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.6.RELEASE/spring-kafka-test-2.2.6.RELEASE.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/Users/qianliqing/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/qianliqing/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/Users/qianliqing/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/Users/qianliqing/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/Users/qianliqing/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/Users/qianliqing/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/Users/qianliqing/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/qianliqing/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger2/2.7.0/springfox-swagger2-2.7.0.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-annotations/1.5.13/swagger-annotations-1.5.13.jar:/Users/qianliqing/.m2/repository/io/swagger/swagger-models/1.5.13/swagger-models-1.5.13.jar:/Users/qianliqing/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spi/2.7.0/springfox-spi-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-core/2.7.0/springfox-core-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-schema/2.7.0/springfox-schema-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-common/2.7.0/springfox-swagger-common-2.7.0.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-spring-web/2.7.0/springfox-spring-web-2.7.0.jar:/Users/qianliqing/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/qianliqing/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/qianliqing/.m2/repository/com/google/guava/guava/18.0/guava-18.0.jar:/Users/qianliqing/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/Users/qianliqing/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/qianliqing/.m2/repository/org/mapstruct/mapstruct/1.1.0.Final/mapstruct-1.1.0.Final.jar:/Users/qianliqing/.m2/repository/io/springfox/springfox-swagger-ui/2.7.0/springfox-swagger-ui-2.7.0.jar:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.library.path=/Users/qianliqing/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.io.tmpdir=/var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:java.compiler=<NA>
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.name=Mac OS X
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.arch=x86_64
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:os.version=10.15.3
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.name=qianliqing
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.home=/Users/qianliqing
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:100 - Client environment:user.dir=/Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:60479 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@758a34ce
2020-03-29 15:08:48 [Thread: main] [ INFO ] ZkClient:936 - Waiting for keeper state SyncConnected
2020-03-29 15:08:48 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:60479. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:08:48 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:60479, initiating session
2020-03-29 15:08:48 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:60480
2020-03-29 15:08:48 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:60480
2020-03-29 15:08:48 [Thread: SyncThread:0] [ INFO ] FileTxnLog:213 - Creating new log file: log.1
2020-03-29 15:08:48 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d7e56a0000 with negotiated timeout 6000 for client /127.0.0.1:60480
2020-03-29 15:08:48 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:60479, sessionid = 0x10002d7e56a0000, negotiated timeout = 6000
2020-03-29 15:08:48 [Thread: main-EventThread] [ INFO ] ZkClient:713 - zookeeper state changed (SyncConnected)
2020-03-29 15:08:48 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6083626373972842472
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:60479
2020-03-29 15:08:49 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:60479.
2020-03-29 15:08:49 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:60479 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@499b2a5c
2020-03-29 15:08:49 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:60479. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:08:49 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:60479, initiating session
2020-03-29 15:08:49 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:60481
2020-03-29 15:08:49 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:60481
2020-03-29 15:08:49 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 15:08:49 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d7e56a0001 with negotiated timeout 6000 for client /127.0.0.1:60481
2020-03-29 15:08:49 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:60479, sessionid = 0x10002d7e56a0001, negotiated timeout = 6000
2020-03-29 15:08:49 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = IXT-dZwRT-SdzbQIPwSuUQ
2020-03-29 15:08:49 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6083626373972842472/meta.properties
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6083626373972842472
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6083626373972842472
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:49 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 15:08:49 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 15:08:49 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 7 ms.
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 15:08:49 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9092.
2020-03-29 15:08:49 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started 1 acceptor threads
2020-03-29 15:08:49 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Starting
2020-03-29 15:08:49 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Starting
2020-03-29 15:08:49 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Starting
2020-03-29 15:08:49 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/0 (is it secure? false)
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/0 is: OK
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 15:08:49 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6083626373972842472/meta.properties
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Starting
2020-03-29 15:08:49 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Starting
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 15:08:49 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Starting
2020-03-29 15:08:49 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Starting
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] 0 successfully elected as the controller
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Reading controller epoch from ZooKeeper
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Incrementing controller epoch in ZooKeeper
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0001 type:setData cxid:0x21 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Epoch incremented to 1
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Registering handlers
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting log dir event notifications
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Deleting isr change notifications
2020-03-29 15:08:49 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Starting up.
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing controller context
2020-03-29 15:08:49 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Startup complete.
2020-03-29 15:08:49 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds.
2020-03-29 15:08:49 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
2020-03-29 15:08:49 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Starting up.
2020-03-29 15:08:49 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Startup complete.
2020-03-29 15:08:49 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions being reassigned: Map()
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently active brokers in the cluster: Set(0)
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Currently shutting brokers in the cluster: Set()
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Current list of topics in the cluster: Set()
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Fetching topic deletions in progress
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics to be deleted: 
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] List of topics ineligible for deletion: 
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Initializing topic deletion manager
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Sending update metadata request
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Initializing replica state
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Started replica state machine with initial state -> Map()
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Initializing partition state
2020-03-29 15:08:49 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9092 (id: 0 rack: null) for sending state change requests
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Triggering online partition state changes
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Started partition state machine with initial state -> Map()
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Ready to serve as the new controller with epoch 1
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0001 type:delete cxid:0x31 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-03-29 15:08:49 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions undergoing preferred replica election: 
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Partitions that completed preferred replica election: 
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Resuming preferred replica election for partitions: 
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting preferred replica leader election for partitions 
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0001 type:delete cxid:0x39 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-03-29 15:08:49 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Started processors for 1 acceptors
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Starting the controller scheduler
2020-03-29 15:08:49 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:08:49 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] started
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3538918978240851635
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:60479
2020-03-29 15:08:49 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:60479.
2020-03-29 15:08:49 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:60479 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@889d9e8
2020-03-29 15:08:49 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:60479. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:08:49 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:60486
2020-03-29 15:08:49 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:60479, initiating session
2020-03-29 15:08:49 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:60486
2020-03-29 15:08:49 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d7e56a0002 with negotiated timeout 6000 for client /127.0.0.1:60486
2020-03-29 15:08:49 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:60479, sessionid = 0x10002d7e56a0002, negotiated timeout = 6000
2020-03-29 15:08:49 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 15:08:49 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x1 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x2 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x3 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x4 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x5 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x6 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x7 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x8 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x9 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0xa zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0xb zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0xc zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 15:08:49 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0xd zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = IXT-dZwRT-SdzbQIPwSuUQ
2020-03-29 15:08:49 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3538918978240851635/meta.properties
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3538918978240851635
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3538918978240851635
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:49 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 15:08:49 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 15:08:49 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 0 ms.
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 15:08:49 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 15:08:49 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9093.
2020-03-29 15:08:49 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started 1 acceptor threads
2020-03-29 15:08:49 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Starting
2020-03-29 15:08:49 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Starting
2020-03-29 15:08:49 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Starting
2020-03-29 15:08:49 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/1 (is it secure? false)
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/1 is: OK
2020-03-29 15:08:49 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 15:08:49 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-3538918978240851635/meta.properties
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 1, deleted brokers: , all live brokers: 0,1
2020-03-29 15:08:49 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Starting
2020-03-29 15:08:49 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 1
2020-03-29 15:08:49 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-03-29 15:08:49 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Starting
2020-03-29 15:08:49 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Starting
2020-03-29 15:08:49 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Starting up.
2020-03-29 15:08:49 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Startup complete.
2020-03-29 15:08:49 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 15:08:49 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2
2020-03-29 15:08:49 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Starting up.
2020-03-29 15:08:49 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Starting
2020-03-29 15:08:49 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Startup complete.
2020-03-29 15:08:49 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Started processors for 1 acceptors
2020-03-29 15:08:50 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:08:50 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] started
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6659499129688916420
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:60479
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:60479.
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:60479 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7186333e
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 15:08:50 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:60479. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:08:50 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:60488
2020-03-29 15:08:50 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:60479, initiating session
2020-03-29 15:08:50 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:60488
2020-03-29 15:08:50 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d7e56a0003 with negotiated timeout 6000 for client /127.0.0.1:60488
2020-03-29 15:08:50 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:60479, sessionid = 0x10002d7e56a0003, negotiated timeout = 6000
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x1 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x2 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x3 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x4 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x5 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x6 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x7 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x8 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x9 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0xa zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0xb zxid:0x3b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0xc zxid:0x3c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0xd zxid:0x3d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = IXT-dZwRT-SdzbQIPwSuUQ
2020-03-29 15:08:50 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6659499129688916420/meta.properties
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6659499129688916420
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6659499129688916420
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:50 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 15:08:50 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 15:08:50 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 1 ms.
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 15:08:50 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9094.
2020-03-29 15:08:50 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started 1 acceptor threads
2020-03-29 15:08:50 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Starting
2020-03-29 15:08:50 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Starting
2020-03-29 15:08:50 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Starting
2020-03-29 15:08:50 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/2 (is it secure? false)
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/2 is: OK
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 15:08:50 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-6659499129688916420/meta.properties
2020-03-29 15:08:50 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 2, deleted brokers: , all live brokers: 0,1,2
2020-03-29 15:08:50 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Starting
2020-03-29 15:08:50 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 15:08:50 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 2
2020-03-29 15:08:50 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-03-29 15:08:50 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Starting
2020-03-29 15:08:50 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Starting
2020-03-29 15:08:50 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Starting up.
2020-03-29 15:08:50 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 15:08:50 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Startup complete.
2020-03-29 15:08:50 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3
2020-03-29 15:08:50 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Starting up.
2020-03-29 15:08:50 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Startup complete.
2020-03-29 15:08:50 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Started processors for 1 acceptors
2020-03-29 15:08:50 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:08:50 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] started
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1552016900308476783
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - Connecting to zookeeper on 127.0.0.1:60479
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Initializing a new session to 127.0.0.1:60479.
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZooKeeper:442 - Initiating client connection, connectString=127.0.0.1:60479 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@363f0ba0
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Waiting until connected.
2020-03-29 15:08:50 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1029 - Opening socket connection to server localhost/127.0.0.1:60479. Will not attempt to authenticate using SASL (unknown error)
2020-03-29 15:08:50 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:879 - Socket connection established to localhost/127.0.0.1:60479, initiating session
2020-03-29 15:08:50 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:215 - Accepted socket connection from /127.0.0.1:60490
2020-03-29 15:08:50 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] ZooKeeperServer:949 - Client attempting to establish new session at /127.0.0.1:60490
2020-03-29 15:08:50 [Thread: SyncThread:0] [ INFO ] ZooKeeperServer:694 - Established session 0x10002d7e56a0004 with negotiated timeout 6000 for client /127.0.0.1:60490
2020-03-29 15:08:50 [Thread: main-SendThread(localhost:60479)] [ INFO ] ClientCnxn:1303 - Session establishment complete on server localhost/127.0.0.1:60479, sessionid = 0x10002d7e56a0004, negotiated timeout = 6000
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Connected.
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0x1 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0x2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0x3 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0x4 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0x5 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0x6 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0x7 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0x8 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0x9 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0xa zxid:0x4a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0xb zxid:0x4b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0xc zxid:0x4c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users
2020-03-29 15:08:50 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:create cxid:0xd zxid:0x4d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - Cluster ID = IXT-dZwRT-SdzbQIPwSuUQ
2020-03-29 15:08:50 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1552016900308476783/meta.properties
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1552016900308476783
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaConfig:279 - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1552016900308476783
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:60479
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2020-03-29 15:08:50 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Starting
2020-03-29 15:08:50 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Starting
2020-03-29 15:08:50 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogManager:66 - Loading logs.
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogManager:66 - Logs loading complete in 1 ms.
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogManager:66 - Starting log cleanup with a period of 300000 ms.
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogManager:66 - Starting log flusher with a default period of 9223372036854775807 ms.
2020-03-29 15:08:50 [Thread: main] [ INFO ] LogCleaner:66 - Starting the log cleaner
2020-03-29 15:08:50 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] Acceptor:66 - Awaiting socket connections on localhost:9095.
2020-03-29 15:08:50 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started 1 acceptor threads
2020-03-29 15:08:50 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Starting
2020-03-29 15:08:50 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Starting
2020-03-29 15:08:50 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Starting
2020-03-29 15:08:50 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaZkClient:66 - Creating /brokers/ids/3 (is it secure? false)
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaZkClient:66 - Result of znode creation at /brokers/ids/3 is: OK
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaZkClient:66 - Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT))
2020-03-29 15:08:50 [Thread: main] [ WARN ] BrokerMetadataCheckpoint:70 - No meta.properties file under dir /var/folders/lb/j5nb3nx16f32n8drg7xdwj7h0000gn/T/kafka-1552016900308476783/meta.properties
2020-03-29 15:08:50 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Starting
2020-03-29 15:08:50 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] Newly added brokers: 3, deleted brokers: , all live brokers: 0,1,2,3
2020-03-29 15:08:50 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Starting
2020-03-29 15:08:50 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Starting
2020-03-29 15:08:50 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Starting
2020-03-29 15:08:50 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Starting
2020-03-29 15:08:50 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=0] New broker startup callback for 3
2020-03-29 15:08:50 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-03-29 15:08:50 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Starting up.
2020-03-29 15:08:50 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Startup complete.
2020-03-29 15:08:50 [Thread: group-metadata-manager-0] [ INFO ] GroupMetadataManager:66 - [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds.
2020-03-29 15:08:50 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4
2020-03-29 15:08:50 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Starting up.
2020-03-29 15:08:50 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Startup complete.
2020-03-29 15:08:50 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Starting
2020-03-29 15:08:50 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Started processors for 1 acceptors
2020-03-29 15:08:50 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:08:50 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] started
2020-03-29 15:08:50 [Thread: main] [ INFO ] AdminClientConfig:279 - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:9092, 127.0.0.1:9093, 127.0.0.1:9094, 127.0.0.1:9095]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2020-03-29 15:08:50 [Thread: main] [ INFO ] AppInfoParser:109 - Kafka version : 2.0.1
2020-03-29 15:08:50 [Thread: main] [ INFO ] AppInfoParser:110 - Kafka commitId : fa14705e51bd2ce5
2020-03-29 15:08:50 [Thread: kafka-admin-client-thread | adminclient-1] [ INFO ] AdminMetadataManager:238 - [AdminClient clientId=adminclient-1] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: Timed out waiting to send the call.
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaTest:50 - Starting KafkaTest on 192.168.0.104 with PID 12743 (started by qianliqing in /Users/qianliqing/Documents/IdeaProjects/message-queue-integration/message-queue-kafka/kafka-producer)
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaTest:675 - No active profile set, falling back to default profiles: default
2020-03-29 15:08:50 [Thread: main] [ WARN ] GenericWebApplicationContext:557 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'kafkaTest': Unsatisfied dependency expressed through field 'kafkaTemplate'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shutting down
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 15:08:50 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 15:08:50 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 15:08:50 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopping socket server request processors
2020-03-29 15:08:50 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Stopped socket server request processors
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shutting down
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 0], shut down completely
2020-03-29 15:08:50 [Thread: main] [ INFO ] KafkaApis:66 - [KafkaApi-0] Shutdown complete.
2020-03-29 15:08:50 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutting down
2020-03-29 15:08:50 [Thread: ExpirationReaper-0-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Stopped
2020-03-29 15:08:50 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-topic]: Shutdown completed
2020-03-29 15:08:50 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutting down.
2020-03-29 15:08:50 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2020-03-29 15:08:50 [Thread: main] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 0]: Shutdown complete
2020-03-29 15:08:50 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutting down
2020-03-29 15:08:50 [Thread: TxnMarkerSenderThread-0] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Stopped
2020-03-29 15:08:50 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 0]: Shutdown completed
2020-03-29 15:08:50 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=0] Shutdown complete.
2020-03-29 15:08:50 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutting down.
2020-03-29 15:08:50 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutting down
2020-03-29 15:08:50 [Thread: ExpirationReaper-0-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Stopped
2020-03-29 15:08:50 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Heartbeat]: Shutdown completed
2020-03-29 15:08:50 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutting down
2020-03-29 15:08:50 [Thread: ExpirationReaper-0-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Stopped
2020-03-29 15:08:50 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Rebalance]: Shutdown completed
2020-03-29 15:08:50 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 0]: Shutdown complete.
2020-03-29 15:08:50 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shutting down
2020-03-29 15:08:50 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 15:08:50 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 15:08:50 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 15:08:50 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutting down
2020-03-29 15:08:50 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 0] shutdown completed
2020-03-29 15:08:50 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutting down
2020-03-29 15:08:50 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2020-03-29 15:08:50 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutting down
2020-03-29 15:08:51 [Thread: ExpirationReaper-0-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Stopped
2020-03-29 15:08:51 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Fetch]: Shutdown completed
2020-03-29 15:08:51 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutting down
2020-03-29 15:08:51 [Thread: ExpirationReaper-0-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Stopped
2020-03-29 15:08:51 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-Produce]: Shutdown completed
2020-03-29 15:08:51 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutting down
2020-03-29 15:08:51 [Thread: ExpirationReaper-0-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Stopped
2020-03-29 15:08:51 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2020-03-29 15:08:51 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=0] Shut down completely
2020-03-29 15:08:51 [Thread: main] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 15:08:51 [Thread: main] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 15:08:51 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 15:08:51 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 15:08:51 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 15:08:51 [Thread: main] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutting down
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Stopped
2020-03-29 15:08:51 [Thread: main] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=0] Shutdown completed
2020-03-29 15:08:51 [Thread: main] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=0] Stopped partition state machine
2020-03-29 15:08:51 [Thread: main] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=0] Stopped replica state machine
2020-03-29 15:08:51 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 15:08:51 [Thread: Controller-0-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 15:08:51 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 15:08:51 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 15:08:51 [Thread: Controller-0-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 15:08:51 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 15:08:51 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 15:08:51 [Thread: Controller-0-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 15:08:51 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 15:08:51 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutting down
2020-03-29 15:08:51 [Thread: Controller-0-to-broker-0-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Stopped
2020-03-29 15:08:51 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=0] Shutdown completed
2020-03-29 15:08:51 [Thread: main] [ INFO ] KafkaController:66 - [Controller id=0] Resigned
2020-03-29 15:08:51 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 15:08:51 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d7e56a0001
2020-03-29 15:08:51 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d7e56a0001
2020-03-29 15:08:51 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002d7e56a0001 closed
2020-03-29 15:08:51 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:60481 which had sessionid 0x10002d7e56a0001
2020-03-29 15:08:51 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d7e56a0001
2020-03-29 15:08:51 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 15:08:51 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Creating /controller (is it secure? false)
2020-03-29 15:08:51 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0003 type:create cxid:0x25 zxid:0x52 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-03-29 15:08:51 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0002 type:create cxid:0x24 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: OK
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] 3 successfully elected as the controller
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Reading controller epoch from ZooKeeper
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initialized controller epoch to 1 and zk version 0
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Incrementing controller epoch in ZooKeeper
2020-03-29 15:08:51 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72060720328081412' does not match current session '72060720328081411'
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-03-29 15:08:51 [Thread: controller-event-thread] [ ERROR] KafkaZkClient$CheckedEphemeral:74 - Error while creating ephemeral at /controller, node already exists and owner '72060720328081412' does not match current session '72060720328081410'
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaZkClient:66 - Result of znode creation at /controller is: NODEEXISTS
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Epoch incremented to 2
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Registering handlers
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting log dir event notifications
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Deleting isr change notifications
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing controller context
2020-03-29 15:08:51 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-03-29 15:08:51 [Thread: Controller-3-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-03-29 15:08:51 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Starting
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions being reassigned: Map()
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently active brokers in the cluster: Set(1, 2, 3)
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Currently shutting brokers in the cluster: Set()
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Current list of topics in the cluster: Set()
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Fetching topic deletions in progress
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics to be deleted: 
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] List of topics ineligible for deletion: 
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Initializing topic deletion manager
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Sending update metadata request
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Initializing replica state
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Triggering online replica state changes
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Started replica state machine with initial state -> Map()
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Initializing partition state
2020-03-29 15:08:51 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9094 (id: 2 rack: null) for sending state change requests
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Triggering online partition state changes
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Started partition state machine with initial state -> Map()
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Ready to serve as the new controller with epoch 2
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removing partitions Set() from the list of reassigned partitions in zookeeper
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
2020-03-29 15:08:51 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9095 (id: 3 rack: null) for sending state change requests
2020-03-29 15:08:51 [Thread: Controller-3-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Controller 3 connected to localhost:9093 (id: 1 rack: null) for sending state change requests
2020-03-29 15:08:51 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:delete cxid:0x37 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions undergoing preferred replica election: 
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Partitions that completed preferred replica election: 
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Skipping preferred replica election for partitions due to topic deletion: 
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Resuming preferred replica election for partitions: 
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting preferred replica leader election for partitions 
2020-03-29 15:08:51 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:653 - Got user-level KeeperException when processing sessionid:0x10002d7e56a0004 type:delete cxid:0x39 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2020-03-29 15:08:51 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Starting the controller scheduler
2020-03-29 15:08:52 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 15:08:52 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 15:08:52 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 15:08:53 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 15:08:53 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 15:08:53 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 15:08:54 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 15:08:54 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutting down socket server
2020-03-29 15:08:54 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=0] Shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=0] shut down completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shutting down
2020-03-29 15:08:54 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 15:08:54 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 15:08:54 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopping socket server request processors
2020-03-29 15:08:54 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Stopped socket server request processors
2020-03-29 15:08:54 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shutting down
2020-03-29 15:08:54 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 1], shut down completely
2020-03-29 15:08:54 [Thread: main] [ INFO ] KafkaApis:66 - [KafkaApi-1] Shutdown complete.
2020-03-29 15:08:54 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutting down
2020-03-29 15:08:54 [Thread: ExpirationReaper-1-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Stopped
2020-03-29 15:08:54 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-topic]: Shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutting down.
2020-03-29 15:08:54 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000
2020-03-29 15:08:54 [Thread: main] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 1]: Shutdown complete
2020-03-29 15:08:54 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutting down
2020-03-29 15:08:54 [Thread: TxnMarkerSenderThread-1] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Stopped
2020-03-29 15:08:54 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 1]: Shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=1] Shutdown complete.
2020-03-29 15:08:54 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutting down.
2020-03-29 15:08:54 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutting down
2020-03-29 15:08:54 [Thread: ExpirationReaper-1-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Stopped
2020-03-29 15:08:54 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Heartbeat]: Shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutting down
2020-03-29 15:08:54 [Thread: ExpirationReaper-1-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Stopped
2020-03-29 15:08:54 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Rebalance]: Shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 1]: Shutdown complete.
2020-03-29 15:08:54 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shutting down
2020-03-29 15:08:54 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 15:08:54 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 15:08:54 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutting down
2020-03-29 15:08:54 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 1] shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutting down
2020-03-29 15:08:54 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 1] shutdown completed
2020-03-29 15:08:54 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutting down
2020-03-29 15:08:55 [Thread: ExpirationReaper-1-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Stopped
2020-03-29 15:08:55 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Fetch]: Shutdown completed
2020-03-29 15:08:55 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutting down
2020-03-29 15:08:55 [Thread: ExpirationReaper-1-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Stopped
2020-03-29 15:08:55 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-Produce]: Shutdown completed
2020-03-29 15:08:55 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutting down
2020-03-29 15:08:55 [Thread: ExpirationReaper-1-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Stopped
2020-03-29 15:08:55 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-1-DeleteRecords]: Shutdown completed
2020-03-29 15:08:55 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=1] Shut down completely
2020-03-29 15:08:55 [Thread: main] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 15:08:55 [Thread: main] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 15:08:55 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 15:08:55 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 15:08:55 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 15:08:55 [Thread: main] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 15:08:55 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutting down
2020-03-29 15:08:55 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Stopped
2020-03-29 15:08:55 [Thread: main] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=1] Shutdown completed
2020-03-29 15:08:55 [Thread: main] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=1] Stopped partition state machine
2020-03-29 15:08:55 [Thread: main] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=1] Stopped replica state machine
2020-03-29 15:08:55 [Thread: main] [ INFO ] KafkaController:66 - [Controller id=1] Resigned
2020-03-29 15:08:55 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 15:08:55 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d7e56a0002
2020-03-29 15:08:55 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d7e56a0002
2020-03-29 15:08:55 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:60486 which had sessionid 0x10002d7e56a0002
2020-03-29 15:08:55 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002d7e56a0002 closed
2020-03-29 15:08:55 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d7e56a0002
2020-03-29 15:08:55 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 15:08:55 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 15:08:55 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Newly added brokers: , deleted brokers: 1, all live brokers: 2,3
2020-03-29 15:08:55 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-03-29 15:08:55 [Thread: Controller-3-to-broker-1-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-03-29 15:08:55 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-03-29 15:08:55 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Broker failure callback for 1
2020-03-29 15:08:55 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removed ArrayBuffer() from list of shutting down brokers.
2020-03-29 15:08:55 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 15:08:55 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 15:08:55 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 15:08:56 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 15:08:56 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 15:08:56 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 15:08:57 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 15:08:57 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 15:08:57 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutting down socket server
2020-03-29 15:08:57 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=1] Shutdown completed
2020-03-29 15:08:57 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=1] shut down completed
2020-03-29 15:08:57 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shutting down
2020-03-29 15:08:57 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 15:08:57 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 15:08:57 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 15:08:57 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopping socket server request processors
2020-03-29 15:08:57 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Stopped socket server request processors
2020-03-29 15:08:57 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shutting down
2020-03-29 15:08:57 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 2], shut down completely
2020-03-29 15:08:57 [Thread: main] [ INFO ] KafkaApis:66 - [KafkaApi-2] Shutdown complete.
2020-03-29 15:08:57 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutting down
2020-03-29 15:08:58 [Thread: ExpirationReaper-2-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-topic]: Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutting down.
2020-03-29 15:08:58 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 2]: Shutdown complete: last producerId assigned 2000
2020-03-29 15:08:58 [Thread: main] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 2]: Shutdown complete
2020-03-29 15:08:58 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutting down
2020-03-29 15:08:58 [Thread: TxnMarkerSenderThread-2] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 2]: Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=2] Shutdown complete.
2020-03-29 15:08:58 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutting down.
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutting down
2020-03-29 15:08:58 [Thread: ExpirationReaper-2-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Heartbeat]: Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutting down
2020-03-29 15:08:58 [Thread: ExpirationReaper-2-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Rebalance]: Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 2]: Shutdown complete.
2020-03-29 15:08:58 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shutting down
2020-03-29 15:08:58 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 15:08:58 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutting down
2020-03-29 15:08:58 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 2] shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutting down
2020-03-29 15:08:58 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 2] shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutting down
2020-03-29 15:08:58 [Thread: ExpirationReaper-2-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Fetch]: Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutting down
2020-03-29 15:08:58 [Thread: ExpirationReaper-2-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-Produce]: Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutting down
2020-03-29 15:08:58 [Thread: ExpirationReaper-2-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-2-DeleteRecords]: Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=2] Shut down completely
2020-03-29 15:08:58 [Thread: main] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 15:08:58 [Thread: main] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 15:08:58 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 15:08:58 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 15:08:58 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutting down
2020-03-29 15:08:58 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Stopped
2020-03-29 15:08:58 [Thread: main] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=2] Shutdown completed
2020-03-29 15:08:58 [Thread: main] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=2] Stopped partition state machine
2020-03-29 15:08:58 [Thread: main] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=2] Stopped replica state machine
2020-03-29 15:08:58 [Thread: main] [ INFO ] KafkaController:66 - [Controller id=2] Resigned
2020-03-29 15:08:58 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 15:08:59 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d7e56a0003
2020-03-29 15:08:59 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d7e56a0003
2020-03-29 15:08:59 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d7e56a0003
2020-03-29 15:08:59 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002d7e56a0003 closed
2020-03-29 15:08:59 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:60488 which had sessionid 0x10002d7e56a0003
2020-03-29 15:08:59 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 15:08:59 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 15:08:59 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Newly added brokers: , deleted brokers: 2, all live brokers: 3
2020-03-29 15:08:59 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-03-29 15:08:59 [Thread: Controller-3-to-broker-2-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-03-29 15:08:59 [Thread: controller-event-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-03-29 15:08:59 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Broker failure callback for 2
2020-03-29 15:08:59 [Thread: controller-event-thread] [ INFO ] KafkaController:66 - [Controller id=3] Removed ArrayBuffer() from list of shutting down brokers.
2020-03-29 15:08:59 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 15:08:59 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 15:08:59 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 15:09:00 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 15:09:00 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 15:09:00 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 15:09:01 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 15:09:01 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutting down socket server
2020-03-29 15:09:01 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=2] Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=2] shut down completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shutting down
2020-03-29 15:09:01 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutting down
2020-03-29 15:09:01 [Thread: /config/changes-event-process-thread] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Stopped
2020-03-29 15:09:01 [Thread: main] [ INFO ] ZkNodeChangeNotificationListener$ChangeEventProcessThread:66 - [/config/changes-event-process-thread]: Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopping socket server request processors
2020-03-29 15:09:01 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Stopped socket server request processors
2020-03-29 15:09:01 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shutting down
2020-03-29 15:09:01 [Thread: main] [ INFO ] KafkaRequestHandlerPool:66 - [Kafka Request Handler on Broker 3], shut down completely
2020-03-29 15:09:01 [Thread: main] [ INFO ] KafkaApis:66 - [KafkaApi-3] Shutdown complete.
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutting down
2020-03-29 15:09:01 [Thread: ExpirationReaper-3-topic] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Stopped
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-topic]: Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutting down.
2020-03-29 15:09:01 [Thread: main] [ INFO ] ProducerIdManager:66 - [ProducerId Manager 3]: Shutdown complete: last producerId assigned 3000
2020-03-29 15:09:01 [Thread: main] [ INFO ] TransactionStateManager:66 - [Transaction State Manager 3]: Shutdown complete
2020-03-29 15:09:01 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutting down
2020-03-29 15:09:01 [Thread: TxnMarkerSenderThread-3] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Stopped
2020-03-29 15:09:01 [Thread: main] [ INFO ] TransactionMarkerChannelManager:66 - [Transaction Marker Channel Manager 3]: Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] TransactionCoordinator:66 - [TransactionCoordinator id=3] Shutdown complete.
2020-03-29 15:09:01 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutting down.
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutting down
2020-03-29 15:09:01 [Thread: ExpirationReaper-3-Heartbeat] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Stopped
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Heartbeat]: Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutting down
2020-03-29 15:09:01 [Thread: ExpirationReaper-3-Rebalance] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Stopped
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Rebalance]: Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] GroupCoordinator:66 - [GroupCoordinator 3]: Shutdown complete.
2020-03-29 15:09:01 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shutting down
2020-03-29 15:09:01 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutting down
2020-03-29 15:09:01 [Thread: LogDirFailureHandler] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Stopped
2020-03-29 15:09:01 [Thread: main] [ INFO ] ReplicaManager$LogDirFailureHandler:66 - [LogDirFailureHandler]: Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutting down
2020-03-29 15:09:01 [Thread: main] [ INFO ] ReplicaFetcherManager:66 - [ReplicaFetcherManager on broker 3] shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutting down
2020-03-29 15:09:01 [Thread: main] [ INFO ] ReplicaAlterLogDirsManager:66 - [ReplicaAlterLogDirsManager on broker 3] shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutting down
2020-03-29 15:09:01 [Thread: ExpirationReaper-3-Fetch] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Stopped
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Fetch]: Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutting down
2020-03-29 15:09:01 [Thread: ExpirationReaper-3-Produce] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Stopped
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-Produce]: Shutdown completed
2020-03-29 15:09:01 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutting down
2020-03-29 15:09:02 [Thread: ExpirationReaper-3-DeleteRecords] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Stopped
2020-03-29 15:09:02 [Thread: main] [ INFO ] DelayedOperationPurgatory$ExpiredOperationReaper:66 - [ExpirationReaper-3-DeleteRecords]: Shutdown completed
2020-03-29 15:09:02 [Thread: main] [ INFO ] ReplicaManager:66 - [ReplicaManager broker=3] Shut down completely
2020-03-29 15:09:02 [Thread: main] [ INFO ] LogManager:66 - Shutting down.
2020-03-29 15:09:02 [Thread: main] [ INFO ] LogCleaner:66 - Shutting down the log cleaner.
2020-03-29 15:09:02 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutting down
2020-03-29 15:09:02 [Thread: kafka-log-cleaner-thread-0] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Stopped
2020-03-29 15:09:02 [Thread: main] [ INFO ] LogCleaner:66 - [kafka-log-cleaner-thread-0]: Shutdown completed
2020-03-29 15:09:02 [Thread: main] [ INFO ] LogManager:66 - Shutdown complete.
2020-03-29 15:09:02 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutting down
2020-03-29 15:09:02 [Thread: controller-event-thread] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Stopped
2020-03-29 15:09:02 [Thread: main] [ INFO ] ControllerEventManager$ControllerEventThread:66 - [ControllerEventThread controllerId=3] Shutdown completed
2020-03-29 15:09:02 [Thread: main] [ INFO ] PartitionStateMachine:66 - [PartitionStateMachine controllerId=3] Stopped partition state machine
2020-03-29 15:09:02 [Thread: main] [ INFO ] ReplicaStateMachine:66 - [ReplicaStateMachine controllerId=3] Stopped replica state machine
2020-03-29 15:09:02 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutting down
2020-03-29 15:09:02 [Thread: Controller-3-to-broker-3-send-thread] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Stopped
2020-03-29 15:09:02 [Thread: main] [ INFO ] RequestSendThread:66 - [RequestSendThread controllerId=3] Shutdown completed
2020-03-29 15:09:02 [Thread: main] [ INFO ] KafkaController:66 - [Controller id=3] Resigned
2020-03-29 15:09:02 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closing.
2020-03-29 15:09:02 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d7e56a0004
2020-03-29 15:09:02 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d7e56a0004
2020-03-29 15:09:02 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:60490 which had sessionid 0x10002d7e56a0004
2020-03-29 15:09:02 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d7e56a0004
2020-03-29 15:09:02 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002d7e56a0004 closed
2020-03-29 15:09:02 [Thread: main] [ INFO ] ZooKeeperClient:66 - [ZooKeeperClient] Closed.
2020-03-29 15:09:02 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutting down
2020-03-29 15:09:02 [Thread: ThrottledChannelReaper-Fetch] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Stopped
2020-03-29 15:09:02 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2020-03-29 15:09:02 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutting down
2020-03-29 15:09:03 [Thread: ThrottledChannelReaper-Produce] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Stopped
2020-03-29 15:09:03 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Produce]: Shutdown completed
2020-03-29 15:09:03 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutting down
2020-03-29 15:09:04 [Thread: ThrottledChannelReaper-Request] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Stopped
2020-03-29 15:09:04 [Thread: main] [ INFO ] ClientQuotaManager$ThrottledChannelReaper:66 - [ThrottledChannelReaper-Request]: Shutdown completed
2020-03-29 15:09:04 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutting down socket server
2020-03-29 15:09:04 [Thread: main] [ INFO ] SocketServer:66 - [SocketServer brokerId=3] Shutdown completed
2020-03-29 15:09:04 [Thread: main] [ INFO ] KafkaServer:66 - [KafkaServer id=3] shut down completed
2020-03-29 15:09:04 [Thread: ZkClient-EventThread-21-127.0.0.1:60479] [ INFO ] ZkEventThread:83 - Terminate ZkClient event thread.
2020-03-29 15:09:04 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] SessionTrackerImpl:199 - Session closing: 0x10002d7e56a0000
2020-03-29 15:09:04 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:487 - Processed session termination for sessionid: 0x10002d7e56a0000
2020-03-29 15:09:04 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxn:1056 - Closed socket connection for client /127.0.0.1:60480 which had sessionid 0x10002d7e56a0000
2020-03-29 15:09:04 [Thread: main] [ INFO ] ZooKeeper:693 - Session: 0x10002d7e56a0000 closed
2020-03-29 15:09:04 [Thread: main-EventThread] [ INFO ] ClientCnxn:522 - EventThread shut down for session: 0x10002d7e56a0000
2020-03-29 15:09:04 [Thread: main] [ INFO ] ZooKeeperServer:502 - shutting down
2020-03-29 15:09:04 [Thread: main] [ INFO ] SessionTrackerImpl:226 - Shutting down
2020-03-29 15:09:04 [Thread: main] [ INFO ] PrepRequestProcessor:769 - Shutting down
2020-03-29 15:09:04 [Thread: ProcessThread(sid:0 cport:60479):] [ INFO ] PrepRequestProcessor:144 - PrepRequestProcessor exited loop!
2020-03-29 15:09:04 [Thread: main] [ INFO ] SyncRequestProcessor:208 - Shutting down
2020-03-29 15:09:04 [Thread: SyncThread:0] [ INFO ] SyncRequestProcessor:186 - SyncRequestProcessor exited!
2020-03-29 15:09:04 [Thread: main] [ INFO ] FinalRequestProcessor:403 - shutdown of request processor complete
2020-03-29 15:09:04 [Thread: NIOServerCxn.Factory:/127.0.0.1:0] [ INFO ] NIOServerCnxnFactory:242 - NIOServerCnxn factory exited run method
2020-03-29 15:09:04 [Thread: main] [ ERROR] LoggingFailureAnalysisReporter:42 - 

***************************
APPLICATION FAILED TO START
***************************

Description:

Field kafkaTemplate in com.qianlq.producer.kafka.KafkaTest required a bean of type 'org.springframework.kafka.core.KafkaTemplate' that could not be found.

The injection point has the following annotations:
	- @org.springframework.beans.factory.annotation.Autowired(required=true)


Action:

Consider defining a bean of type 'org.springframework.kafka.core.KafkaTemplate' in your configuration.

2020-03-29 15:09:04 [Thread: main] [ ERROR] TestContextManager:250 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@3e27ba32] to prepare test instance [com.qianlq.producer.kafka.KafkaTest@3e104d4b]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:125) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) [spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) [junit-4.12.jar:4.12]
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) [junit-rt.jar:?]
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) [junit-rt.jar:?]
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) [junit-rt.jar:?]
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) [junit-rt.jar:?]
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'kafkaTest': Unsatisfied dependency expressed through field 'kafkaTemplate'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:843) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	... 24 more
Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.kafka.core.KafkaTemplate<java.lang.String, java.lang.String>' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1655) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1214) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1168) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1411) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:592) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:843) ~[spring-beans-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) ~[spring-context-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) ~[spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) ~[spring-boot-test-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.7.RELEASE.jar:5.1.7.RELEASE]
	... 24 more
